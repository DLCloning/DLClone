{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugT1qQ0XEW8U"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1MRzBLtex2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0256f205-4347-4f3a-a815-d79e753351d5"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "!pip install -qU t5\n",
        "\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_block_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "!pip install tensorflow-gcs-config\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "     |████████████████████████████████| 153 kB 5.3 MB/s            \n",
            "     |████████████████████████████████| 1.2 MB 30.4 MB/s            \n",
            "     |████████████████████████████████| 90 kB 11.0 MB/s            \n",
            "     |████████████████████████████████| 366 kB 81.7 MB/s            \n",
            "     |████████████████████████████████| 4.0 MB 75.0 MB/s            \n",
            "     |████████████████████████████████| 4.9 MB 64.4 MB/s            \n",
            "     |████████████████████████████████| 3.1 MB 50.8 MB/s            \n",
            "     |████████████████████████████████| 286 kB 83.5 MB/s            \n",
            "     |████████████████████████████████| 59 kB 5.7 MB/s             \n",
            "     |████████████████████████████████| 895 kB 75.5 MB/s            \n",
            "     |████████████████████████████████| 596 kB 80.9 MB/s            \n",
            "     |████████████████████████████████| 3.3 MB 71.1 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-gcs-config in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.12.62.226:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poax9QWkEeMV"
      },
      "source": [
        "### Loading of the tsv files\n",
        "We loaded the tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "\n",
        "nq_tsv_path = {\n",
        "    \"train\":      'gs://bucket_block_completion/dataset_08_07/train.tsv',\n",
        "    \"validation\": 'gs://bucket_block_completion/dataset_08_07/eval.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples = dict(train=1197310, validation=15783)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Y8Tje7FiNi"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WK7uMr3zYuQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_block_completion/code.model'\n",
        "vocab_path = 'gs://bucket_block_completion/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP4yvsTe4oAH"
      },
      "source": [
        "## If you have more than one task you have to use the prefix, otherwise it is not mandatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGp5FiN1yFQ",
        "outputId": "7346e2e2-08d5-4430-bc7e-4505c2ec336a"
      },
      "source": [
        "prefix=''\n",
        "\n",
        "def nq_dataset_task(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_task(\"train\").take(5)):\n",
        "    print(ex)\n",
        "\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join([prefix + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label}\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "      \n",
        "t5.data.TaskRegistry.remove('finetuning')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"finetuning\",\n",
        "    dataset_fn=nq_dataset_task,\n",
        "    splits=[\"train\",\"validation\"],\n",
        "    text_preprocessor=preprocessing,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'public static void saveBitmapToDevice(Bitmap btmp, String filePath, String imageName) { File file = new File (filePath, imageName); if (file.exists ()) file.delete (); try <extra_id_0> catch (Exception e) { e.printStackTrace(); } }', 'output': b'{ FileOutputStream out = new FileOutputStream(file); btmp.compress(Bitmap.CompressFormat.JPEG, 90, out); out.flush(); out.close(); }'}\n",
            "{'input': b'@Override public Dampening updateGroupDampening(String tenantId, Dampening groupDampening) throws Exception { if (isEmpty(tenantId)) { throw new IllegalArgumentException(\"TenantId must be not null\"); } if (isEmpty(groupDampening)) { throw new IllegalArgumentException(\"DampeningId and TriggerId must be not null\"); } try { deferNotifications(); checkTenantId(tenantId, groupDampening); String groupId = groupDampening.getTriggerId(); Trigger groupTrigger = getTrigger(tenantId, groupId); if (!groupTrigger.isGroup()) { throw new IllegalArgumentException( \"Trigger [\" + tenantId + \"/\" + groupId + \"] is not a group trigger.\"); } Collection<Trigger> memberTriggers = getMemberTriggers(tenantId, groupId, false); for (Trigger member : memberTriggers) <extra_id_0> groupDampening.setTriggerId(groupTrigger.getId()); return updateDampening(groupDampening); } finally { releaseNotifications(); } }', 'output': b'{ groupDampening.setTriggerId(member.getId()); updateDampening(groupDampening); }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) <extra_id_0> return rv.toString(); } return toXMLString(); }', 'output': b'{ XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) { XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); } }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) { XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) <extra_id_0> } return rv.toString(); } return toXMLString(); }', 'output': b'{ XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); }'}\n",
            "{'input': b'private void getClassAnnotationsFromDTO(Object config, DTODescription description) <extra_id_0>', 'output': b'{ Annotation[] declaredAnnotations = getTemplateClass(config).getDeclaredAnnotations(); if (declaredAnnotations != null) { for (Annotation annotation : declaredAnnotations) { description.addAnnotation(annotation); } } }'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f52c076bb90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-GatnV2dLG",
        "outputId": "413a0064-2c4a-4cd9-a7b7-fc200372eab6"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"finetuning\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'@Nonnull public QValue getQValueOfLanguage (@Nonnull final String sLanguage) { ValueEnforcer.notNull (sLanguage, \"Language\"); QValue aQuality = m_aMap.get (_unify (sLanguage)); if (aQuality == null) <extra_id_0> return aQuality; }', 'inputs': array([   19,   790,    12,     3,     2,   106,    41,     2,   106,\n",
            "         432,  1354,     3,   261,   790,    44,    26,     3,    22,\n",
            "        1354,     8,     7,     3,   106, 30104,     4,  2623,    17,\n",
            "          22,  1354,     9,    32,  1354,    46,     3,     2,   106,\n",
            "         107,     2,  3145,    11,    54,    15,   184,   100,     4,\n",
            "          33,    17,    15,  1284,  3647,    17,    22,  1354,    79,\n",
            "          21,    17,   184,     2,  3145,    40,    30,     8, 32099,\n",
            "          14,   107,     2,  3145,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ aQuality = m_aMap.get (AcceptLanguageHandler.ANY_LANGUAGE); if (aQuality == null) { return QValue.MIN_QVALUE; } }', 'targets': array([   7,  107,    2, 3145,   11,   54,   15,  184,  100,    4,   33,\n",
            "         17, 3071, 1354,  192,    4, 3612,    2,   15, 8615,   10,   21,\n",
            "         17,  184,    2, 3145,   40,   30,    8,    7,   14,    3,    2,\n",
            "        106,    4, 2425,   15,    2,  796,   13,    6,    6,    1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'@Override public void setEnabled(final boolean enabled) { if (enabled) { uiObject.removeStyleName(Styles.DISABLED); uiObject.getElement().removeAttribute(DISABLED); } else <extra_id_0> }', 'inputs': array([   19,    27,    12,    20, 13315,     5,    64,    45,  1621,\n",
            "           8,     7,    21,    17,  1939,     8,     7, 21735,     4,\n",
            "       27966,     5, 10216,     4,  9970,    10, 21735,     4,  3574,\n",
            "          37, 13140,     5,  9970,    10,     6,    77, 32099,     6,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'{ uiObject.addStyleName(Styles.DISABLED); uiObject.getElement().setAttribute(DISABLED, \"\"); }', 'targets': array([    7, 21735,     4, 14171,     5, 10216,     4,  9970,    10,\n",
            "       21735,     4,  3574,    37,  2413,     5,  9970,     9,  1828,\n",
            "           6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public void shouldReturnCommaSeparatedNumberOfCurrentVersionDownloads() throws Exception <extra_id_0>', 'inputs': array([   12,    20,   552,  1700, 24335,  3545,  1211,   263,  9121,\n",
            "          16,    42,   172, 32099,     1], dtype=int32), 'targets_pretokenized': b'{ when(gem.getVersionDownloads()).thenReturn(1000D); assertThat(gemViewModel.getVersionDownloads(), is(\"1,000\")); }', 'targets': array([    7,   707,     5, 23964,     4,  2619,  9121,   588,  1120,\n",
            "        2144,     5,  5853,   228,    10,  1449,     5, 23964,  3313,\n",
            "           4,  2619,  9121,    72,    69,    28,   329,  3862,   295,\n",
            "           6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'@SuppressWarnings(\"unchecked\") public void sSet(SField sField, Object val) { if (sField.getName().equals(\"name\")) { setName((String)val); return; } if (sField.getName().equals(\"pluginClassName\")) { setPluginClassName((String)val); return; } if (sField.getName().equals(\"description\")) { setDescription((String)val); return; } if (sField.getName().equals(\"location\")) { setLocation((String)val); return; } if (sField.getName().equals(\"enabled\")) { setEnabled((Boolean)val); return; } if (sField.getName().equals(\"pluginInterfaceClassName\")) { setPluginInterfaceClassName((String)val); return; } if (sField.getName().equals(\"configurations\")) { setConfigurations((List<Long>)val); return; } if (sField.getName().equals(\"identifier\")) { setIdentifier((String)val); return; } if (sField.getName().equals(\"installForNewUsers\")) { setInstallForNewUsers((Boolean)val); return; } if (sField.getName().equals(\"pluginBundleVersionId\")) { setPluginBundleVersionId((Long)val); return; } if (sField.getName().equals(\"settingsId\")) { setSettingsId((Long)val); return; } if (sField.getName().equals(\"oid\")) <extra_id_0> if (sField.getName().equals(\"rid\")) { setRid((Integer)val); return; } throw new RuntimeException(\"Field \" + sField.getName() + \" not found\"); }', 'inputs': array([   19,   582,    28,   932,   118,    12,    20,     3,    22,\n",
            "         174,     5,   113,   219,     3,    22,   219,     9,   102,\n",
            "         752,     8,     7,    21,    17,    22,   219,     4,   154,\n",
            "          37,   117,    28,    98,   425,     7,  5492,     5,     5,\n",
            "          31,     8,  1102,    10,    14,    13,     6,    21,    17,\n",
            "          22,   219,     4,   154,    37,   117,    28,  1329,  1247,\n",
            "         425,     7,    55,   728,  1247,     5,     5,    31,     8,\n",
            "        1102,    10,    14,    13,     6,    21,    17,    22,   219,\n",
            "           4,   154,    37,   117,    28,  1141,   425,     7,  8539,\n",
            "           5,     5,    31,     8,  1102,    10,    14,    13,     6,\n",
            "          21,    17,    22,   219,     4,   154,    37,   117,    28,\n",
            "        1219,   425,     7, 15758,     5,     5,    31,     8,  1102,\n",
            "          10,    14,    13,     6,    21,    17,    22,   219,     4,\n",
            "         154,    37,   117,    28,  1939,   425,     7, 13315,     5,\n",
            "           5,   649,     8,  1102,    10,    14,    13,     6,    21,\n",
            "          17,    22,   219,     4,   154,    37,   117,    28,  1329,\n",
            "         902,  1247,   425,     7,    55,   728,   902,  1247,     5,\n",
            "           5,    31,     8,  1102,    10,    14,    13,     6,    21,\n",
            "          17,    22,   219,     4,   154,    37,   117,    28,  1382,\n",
            "          22,   425,     7,    55,  7535,     5,     5,    71,    25,\n",
            "         397,    29,     8,  1102,    10,    14,    13,     6,    21,\n",
            "          17,    22,   219,     4,   154,    37,   117,    28,  2455,\n",
            "         425,     7,    55,   660,     5,     5,    31,     8,  1102,\n",
            "          10,    14,    13,     6,    21,    17,    22,   219,     4,\n",
            "         154,    37,   117,    28,  4012, 21544,  2178,   425,     7,\n",
            "          55,  2820, 21544,  2178,     5,     5,   649,     8,  1102,\n",
            "          10,    14,    13,     6,    21,    17,    22,   219,     4,\n",
            "         154,    37,   117,    28,  1329,   674,   263,    68,   425,\n",
            "           7,    55,   728,   674,   263,    68,     5,     5,   397,\n",
            "           8,  1102,    10,    14,    13,     6,    21,    17,    22,\n",
            "         219,     4,   154,    37,   117,    28,  1636,    68,   425,\n",
            "           7,    55,   460,    68,     5,     5,   397,     8,  1102,\n",
            "          10,    14,    13,     6,    21,    17,    22,   219,     4,\n",
            "         154,    37,   117,    28,  8039,   425, 32099,    21,    17,\n",
            "          22,   219,     4,   154,    37,   117,    28, 11034,   425,\n",
            "           7,    55,   144,   111,     5,     5,   283,     8,  1102,\n",
            "          10,    14,    13,     6,    78,    24,     3,   468,    28,\n",
            "         219,    32,    34,     3,    22,   219,     4,   154,    16,\n",
            "          34,    32,   153,   807,    46,     6,     1], dtype=int32), 'targets_pretokenized': b'{ setOid((Long)val); return; }', 'targets': array([   7,   55, 4348,    5,    5,  397,    8, 1102,   10,   14,   13,\n",
            "          6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public boolean getExclusiveMax() <extra_id_0>', 'inputs': array([   12,    45,    41, 10955,  1005,    16, 32099,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'{ if (property instanceof AbstractNumericProperty) { AbstractNumericProperty numericProperty = (AbstractNumericProperty) property; return BooleanUtils.isTrue((numericProperty.getExclusiveMaximum())); } return false; }', 'targets': array([    7,    21,    17,  1238,   166,   942,  3996,   220,     8,\n",
            "           7,   942,  3996,   220, 10463,   220,    11,    17,  1296,\n",
            "        3996,   220,     8,   698,    13,    14,   536,   217,     4,\n",
            "        6621,     5,     5, 14405,   220,     4,    33, 10955,  8235,\n",
            "         366,     6,    14,    76,    13,     6,     1], dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkLJ-FpDF8CD"
      },
      "source": [
        "### Hyper Parameter tuning\n",
        "You can run the HP tuning using the following cells.  \n",
        "Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in), *PATH_GIN_FILE* (the gin file configuration for this HP tuning) and *PRETRAINED_DIR* (the folder that contains the pretrained model).  \n",
        "**Keep attention** to change the *pretrained_model_dir* in finetune step (if you are starting the HP tuning from scratch you have to set the value *PRETRAINED_DIR*, if you are restarting the HP tuning from a previous saved checkpoint you have to set the value *MODEL_DIR*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1a1TxFNKmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ce2206-ae4b-45f3-9fa9-c70d717efb45"
      },
      "source": [
        "## this is useful if you have more than one task\n",
        "# def _rate_num_input_examples(task):\n",
        "#   if \"train\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"train\"))\n",
        "#   elif \"validation\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"validation\"))\n",
        "#   else:\n",
        "#     raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "# t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "# t5.data.MixtureRegistry.add(\n",
        "#     \"all_tasks\",\n",
        "#     [\"java_construct\", \"java_token\", \"java_block\", \"android_construct\", \"android_token\", \"android_block\"],\n",
        "#     default_rate=_rate_num_input_examples\n",
        "#      #default_rate=1.0\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.seqio.dataset_providers.Mixture at 0x7f4a4465d470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTFQyksoK6-Z"
      },
      "source": [
        "SLANTED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/HP_TUNING/slanted/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKeCgqAkKIDO",
        "outputId": "92205cd8-e914-4d54-ab80-8104643d278c"
      },
      "source": [
        "# we used model.predict function (setting beam_size)\n",
        "\n",
        "vocabulary_predict=get_default_vocabulary()\n",
        "\n",
        "model.predict(input_file='gs://bucket_block_completion/HP_TUNING/slanted/model/validation_eval/finetuning_inputs', output_file='gs://bucket_block_completion/HP_TUNING/slanted/model/validation_eval/predictions.txt',\n",
        "              checkpoint_steps=250000, beam_size=1, temperature=0.0, keep_top_k=-1, vocabulary=vocabulary_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/HP_TUNING/slanted/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/HP_TUNING/slanted/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/HP_TUNING/slanted/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.126.119.98:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.126.119.98:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.126.119.98:8470', '_evaluation_master': 'grpc://10.126.119.98:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f79215ec3d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.126.119.98:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.126.119.98:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2145149358050436496)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2289362690477258542)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6113157848959202505)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117169904011463996)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8060518372700739672)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -8776614532771633805)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7389421877771732928)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5570189516125609195)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -1306589469090778983)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 4805446315722528345)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -1394328308846867784)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('batch', 'batch'), ('ensemble', 'ensemble'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f791d4c9690>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 2.1e+06\n",
            " allconcat/0: 2.1e+06\n",
            "  allconcat/0/reshape_op: 2.1e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 1.35e+13\n",
            "einsum_unique: 1.35e+13\n",
            "output: 1.35e+11\n",
            " output/AddOperation: 3.44e+10\n",
            " output/BinaryOpWithBroadcasting: 4.56e+08\n",
            " output/Constant: 8.05e+08\n",
            " output/EinsumOperation: 3.07e+10\n",
            " output/ImportOperation: 1.05e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 9.23e+09\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 4.19e+07\n",
            " output/ReshapeOperation: 6.92e+09\n",
            " output/ScalarAddOperation: 5.45e+07\n",
            " output/ScalarMultiplyOperation: 5.75e+08\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 4.12e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 9.66e+09\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 8.05e+08\n",
            "output_unique: 1.33e+11\n",
            " output_unique/AddOperation: 3.43e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.12e+08\n",
            " output_unique/Constant: 8.05e+08\n",
            " output_unique/EinsumOperation: 3.05e+10\n",
            " output_unique/ImportOperation: 1.31e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 8.52e+09\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 4.19e+07\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 1.05e+07\n",
            " output_unique/ScalarMultiplyOperation: 4.87e+08\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 4.09e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 9.66e+09\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 8.05e+08\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/HP_TUNING/slanted/model/model.ckpt-250000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:825: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { total += nread; obuff[nread] = ubuff[nread]; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { byte[] newobuff = new byte[total + nread]; System.arraycopy(obuff, 0, newobuff, 0, total); obuff = newobuff; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { File artifactFile = new File(containerArtifact.getFile()); if (artifactFile.exists()) { File dependencyFile = new File(artifactFile.getParentFile(), \"deploy\"); dependencyLocations.add(dependencyFile.toURI().toURL()); } }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { xmin = Math.min(xmin, this.coordsProperty.get(i)); ymin = Math.max(ymin, this.coordsProperty.get(i+1)); zmin = Math.min(zmin, this.coordsProperty.get(i+2)); ymax = Math.max(ymax, this.coordsProperty.get(i+2)); zmax = Math.max(zmax, this.coordsProperty.get(i+2)); }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest requestWithValidToken = resolve(request, registrationId); return requestWithValidToken != null  ⁇  requestWithValidToken : null; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String groupFormattedDate = commentGroups.get(group.getFormattedDate()); group.setFormattedDate(groupFormattedDate); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { for (int i = 0; i < this.size(); i++) { if (this.get(i).isReturn()) { return true; } } return false; }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma instanceof AndroidRepaintListener) { ((AndroidRepaintListener) ma).onResume(); } post(new Runnable() { public void run() { ma.invalidate(); } }); }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { b ⁇ b ⁇ mapBlendEnabled = enabled; if (enabled) { b ⁇ mapBlendEnabled = false; } else { b ⁇ mapBlendEnabled = false; } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getInfo().getInfo().getName()); sb.append(\" \"); sb.append(treeWalk.getInfo().getVersion()); sb.append(\" \"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { List<Block.Instance> allInstances = new ArrayList<>(); for (Block block : blocks) { allInstances.add(block.getInstance()); } return allInstances; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(candidate); break; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { if (!containsInGroupColumn(updatedColumns, column.getColumnName())) { addColumns.add(column); } } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (59, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPuMPVmaTNBY"
      },
      "source": [
        "CONSTANT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWwyVYA2TRRc"
      },
      "source": [
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/HP_TUNING/constant/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeyLQnulTRTr",
        "outputId": "0d524c0d-06f7-46f7-faf9-9815c17a4548"
      },
      "source": [
        "# we used model.predict function (setting beam_size)\n",
        "\n",
        "vocabulary_predict=get_default_vocabulary()\n",
        "\n",
        "model.predict(input_file='gs://bucket_block_completion/HP_TUNING/constant/model/validation_eval/finetuning_inputs', output_file='gs://bucket_block_completion/HP_TUNING/constant/model/validation_eval/predictions.txt',\n",
        "              checkpoint_steps=250000, beam_size=1, temperature=0.0, keep_top_k=-1, vocabulary=vocabulary_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/HP_TUNING/constant/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/HP_TUNING/constant/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/HP_TUNING/constant/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.126.119.98:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.126.119.98:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.126.119.98:8470', '_evaluation_master': 'grpc://10.126.119.98:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f791be986d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.126.119.98:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.126.119.98:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2145149358050436496)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2289362690477258542)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6113157848959202505)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117169904011463996)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8060518372700739672)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -8776614532771633805)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7389421877771732928)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5570189516125609195)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -1306589469090778983)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 4805446315722528345)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -1394328308846867784)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('batch', 'batch'), ('ensemble', 'ensemble'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f791caa7910>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 2.1e+06\n",
            " allconcat/0: 2.1e+06\n",
            "  allconcat/0/reshape_op: 2.1e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 1.35e+13\n",
            "einsum_unique: 1.35e+13\n",
            "output: 1.35e+11\n",
            " output/AddOperation: 3.44e+10\n",
            " output/BinaryOpWithBroadcasting: 4.56e+08\n",
            " output/Constant: 8.05e+08\n",
            " output/EinsumOperation: 3.07e+10\n",
            " output/ImportOperation: 1.05e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 9.23e+09\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 4.19e+07\n",
            " output/ReshapeOperation: 6.92e+09\n",
            " output/ScalarAddOperation: 5.45e+07\n",
            " output/ScalarMultiplyOperation: 5.75e+08\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 4.12e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 9.66e+09\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 8.05e+08\n",
            "output_unique: 1.33e+11\n",
            " output_unique/AddOperation: 3.43e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.12e+08\n",
            " output_unique/Constant: 8.05e+08\n",
            " output_unique/EinsumOperation: 3.05e+10\n",
            " output_unique/ImportOperation: 1.31e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 8.52e+09\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 4.19e+07\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 1.05e+07\n",
            " output_unique/ScalarMultiplyOperation: 4.87e+08\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 4.09e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 9.66e+09\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 8.05e+08\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/HP_TUNING/constant/model/model.ckpt-250000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { obuff[total++] = nread; total += nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { log.warn(\"Nexrad2 read \"+raf.getLocation()); continue; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL dependencyUrl = plugin ⁇ mlDocument.toURL(); dependencyLocations.add(dependencyUrl); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { xmin = this.coordsProperty.get(i); ymin = this.coordsProperty.get(i); zmin = this.coordsProperty.get(i); zmax = this.coordsProperty.get(i); zmax = this.coordsProperty.get(i); }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest requestWithAuthorization = new OAuth2AuthorizationRequest(request, registrationId); requestWithAuthorization.setAuthorization(true); return requestWithAuthorization; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { group.setReportedDate(comment.getFormattedDate()); commentGroups.put(group.getFormattedDate(), group); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (this.b ⁇  == null) { this.b ⁇  = new Boolean(this.b ⁇ ); } return this.b ⁇ .contains(this.b ⁇ ); }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma instanceof AndroidRepaintListener) { ((AndroidRepaintListener) ma).onResume(); } post(new Runnable() { public void run() { ma.invalidate(); } }); }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (enabled) { b ⁇ .setBlendEnabled(true); } else { b ⁇ .setBlendEnabled(false); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getRev()); sb.append(\" \"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { List<Block.Instance> allInstances = new ArrayList<Block.Instance>(); for (Block.Instance instance : this) { allInstances.add(instance); } return allInstances; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(candidate); candidateSubTypes.add(candidate); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { if (!pks.contains(column.getColumnName())) { column.setUpdate(true); } } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { mItemsAdapter.sortItemsByPurchaseDate(getContext()); mItemsAdapter.notifyDataSetChanged(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 ) { ch=readChar(); } return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (59, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyASJ5pZWJhb"
      },
      "source": [
        "ISR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIb_Ryf9WXHA"
      },
      "source": [
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/HP_TUNING/ISR/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdCAgBs4WIiK",
        "outputId": "0df6d521-05e1-400e-884b-b203da62a8ff"
      },
      "source": [
        "# we used model.predict function (setting beam_size)\n",
        "\n",
        "vocabulary_predict=get_default_vocabulary()\n",
        "\n",
        "model.predict(input_file='gs://bucket_block_completion/HP_TUNING/ISR/model/validation_eval/finetuning_inputs', output_file='gs://bucket_block_completion/HP_TUNING/ISR/model/validation_eval/predictions.txt',\n",
        "              checkpoint_steps=250000, beam_size=1, temperature=0.0, keep_top_k=-1, vocabulary=vocabulary_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/HP_TUNING/ISR/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/HP_TUNING/ISR/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/HP_TUNING/ISR/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.126.119.98:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.126.119.98:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.126.119.98:8470', '_evaluation_master': 'grpc://10.126.119.98:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f791b6cfed0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.126.119.98:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.126.119.98:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2145149358050436496)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2289362690477258542)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6113157848959202505)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 9117169904011463996)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8060518372700739672)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -8776614532771633805)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7389421877771732928)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5570189516125609195)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -1306589469090778983)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 4805446315722528345)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -1394328308846867784)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('batch', 'batch'), ('ensemble', 'ensemble'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f791862ac10>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 2.1e+06\n",
            " allconcat/0: 2.1e+06\n",
            "  allconcat/0/reshape_op: 2.1e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 1.35e+13\n",
            "einsum_unique: 1.35e+13\n",
            "output: 1.35e+11\n",
            " output/AddOperation: 3.44e+10\n",
            " output/BinaryOpWithBroadcasting: 4.56e+08\n",
            " output/Constant: 8.05e+08\n",
            " output/EinsumOperation: 3.07e+10\n",
            " output/ImportOperation: 1.05e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 9.23e+09\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 4.19e+07\n",
            " output/ReshapeOperation: 6.92e+09\n",
            " output/ScalarAddOperation: 5.45e+07\n",
            " output/ScalarMultiplyOperation: 5.75e+08\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 4.12e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 9.66e+09\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 8.05e+08\n",
            "output_unique: 1.33e+11\n",
            " output_unique/AddOperation: 3.43e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.12e+08\n",
            " output_unique/Constant: 8.05e+08\n",
            " output_unique/EinsumOperation: 3.05e+10\n",
            " output_unique/ImportOperation: 1.31e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 8.52e+09\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 4.19e+07\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 1.05e+07\n",
            " output_unique/ScalarMultiplyOperation: 4.87e+08\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 4.09e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 9.66e+09\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 8.05e+08\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/HP_TUNING/ISR/model/model.ckpt-250000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { obuff[total++] = ubuff[nread]; total += nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { obuff = new byte[ ⁇ 0000]; System.arraycopy(obuff, 0, obuff, offset, obuff.length); }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { try { dependencyLocations.add(containerArtifact.getFile().toURI().toURL()); } catch (MalformedURLException e) { throw new MojoFailureException(e); } }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { xmin = this.coordsProperty.get(i); ymin = this.coordsProperty.get(i+2); zmin = this.coordsProperty.get(i+2); xmax = this.coordsProperty.get(i+2); ymax = this.coordsProperty.get(i+2); zmax = this.coordsProperty.get(i+2); }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest requestWithAuthorization = new OAuth2AuthorizationRequest(request, registrationId); return requestWithAuthorization; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String date = commentGroups.get(group.getFormattedDate()); group.setCreationDate(date); commentGroups.put(group.getFormattedDate(), group); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (this.getReturn() == null) { return false; } return this.getReturn().containsReturn(this.getReturn()); }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma instanceof AndroidRepaintListener) { ((AndroidRepaintListener) ma).onResume(); } post(new Runnable() { public void run() { ma.invalidate(); } }); }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (enabled) { b ⁇ b ⁇ mask.setBlendEnabled(true); } else { b ⁇ b ⁇ mask.setBlendEnabled(false); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getRevName()); sb.append(treeIndex); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { List<Block.Instance> allInstances = new ArrayList<Block.Instance>(); allInstances.addAll(block.getAllInstances()); allInstances.addAll(block.getAllInstances()); allInstances.addAll(block.getAllInstances()); return allInstances; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(candidate); typeMetadataByDiscriminator.put(discriminator, candidateSubTypes); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { updatedColumns.add(column.getColumnName()); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇  ) { ch=readChar(); } return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (59, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng_nXDtUId_z"
      },
      "source": [
        "POLYNOMIAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62shhxZyTRV8"
      },
      "source": [
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/HP_TUNING/polynomial/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hpYKo9GTRYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b7ce00-63c7-4078-d88a-98e7d53840b2"
      },
      "source": [
        "# we used model.predict function (setting beam_size)\n",
        "\n",
        "vocabulary_predict=get_default_vocabulary()\n",
        "\n",
        "model.predict(input_file='gs://bucket_block_completion/HP_TUNING/polynomial/model/validation_eval/finetuning_inputs', output_file='gs://bucket_block_completion/HP_TUNING/polynomial/model/validation_eval/predictions.txt',\n",
        "              checkpoint_steps=250000, beam_size=1, temperature=0.0, keep_top_k=-1, vocabulary=vocabulary_predict)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/HP_TUNING/polynomial/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/HP_TUNING/polynomial/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/HP_TUNING/polynomial/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.12.62.226:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.12.62.226:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.12.62.226:8470', '_evaluation_master': 'grpc://10.12.62.226:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f5050765510>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.12.62.226:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.12.62.226:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2274527286961236760)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -2249521377216204403)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4682387980706324894)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -8389736021869169477)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4641326338983534086)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -2665014834099073890)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2865031703426353382)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -6693062059518052117)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -9013389144393483647)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 4288820566354290753)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 8328355289818144492)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('d_ff', 'model'), ('experts', 'batch'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f504c8a9950>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 2.1e+06\n",
            " allconcat/0: 2.1e+06\n",
            "  allconcat/0/reshape_op: 2.1e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 1.35e+13\n",
            "einsum_unique: 1.35e+13\n",
            "output: 1.35e+11\n",
            " output/AddOperation: 3.44e+10\n",
            " output/BinaryOpWithBroadcasting: 4.56e+08\n",
            " output/Constant: 8.05e+08\n",
            " output/EinsumOperation: 3.07e+10\n",
            " output/ImportOperation: 1.05e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 9.23e+09\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 4.19e+07\n",
            " output/ReshapeOperation: 6.92e+09\n",
            " output/ScalarAddOperation: 5.45e+07\n",
            " output/ScalarMultiplyOperation: 5.75e+08\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 4.12e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 9.66e+09\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 8.05e+08\n",
            "output_unique: 1.33e+11\n",
            " output_unique/AddOperation: 3.43e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.12e+08\n",
            " output_unique/Constant: 8.05e+08\n",
            " output_unique/EinsumOperation: 3.05e+10\n",
            " output_unique/ImportOperation: 1.31e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 8.52e+09\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 4.19e+07\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 1.05e+07\n",
            " output_unique/ScalarMultiplyOperation: 4.87e+08\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 4.09e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 9.66e+09\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 8.05e+08\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/HP_TUNING/polynomial/model/model.ckpt-250000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:825: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { if (i == 0) { out.put(i, 0, i); } }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { if (obuff.length >= 0) { obuff[i] = new ByteArrayInputStream(i); } }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { if (containerArtifact != null) { return new ArrayList<URL>(containerArtifact); } }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double xmin = Double.NEGATIVE_INFINIT  ⁇ ; double ymax = Double.NEGATIVE_INFINIT  ⁇ ; double ymax = Double.NEGATIVE_INFINIT  ⁇ ; double ymax = Double.NEGATIVE_INFINIT  ⁇ ; double ymax = ymax = ymax; ymax = ymax; ymax = ymax; }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (registrationId == null) { return this.registrationId; } }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { commentGroups.put(commentGroups); commentGroups.put(group.getFormattedDate(), group.getFormattedDate(), group.get(group.getFormattedDate(), group.getFormattedDate(), commentGroups); commentGroups.put(group.get(group.getFormattedDate(), group.getFormattedDate(), group.get(group.getFormattedDate(), group.getFormattedDate(), commentGroups); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { return true; }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma.isResumed()) { return; } }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (enabled != false) { if (disabled && !disabled && !disabled && !b ⁇  ⁇ .disabled && !b  ⁇ disabled && !b  ⁇ ) { b  ⁇ .disabled(b  ⁇ .disabled); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeIndex); sb.append(treeWalk.append(treeIndex); sb.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.append(treeWalk.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (this.instance.getInstances().isEmpty()) { return Instance.getInstance(this.instance.getInstances()); } return Instance.getInstance(this.instance.getInstances().get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.instance.get(this.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { if (candidateMetadata == null) { return new DynamicType<EntityMetadata(candidateMetadataByDiscriminator(candidateMetadata); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { if (!CollectionUtils.isEmpty(column.getColumnName().getName()); } else { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!StringUtils.isEmpty(column.getColumnName().getName()) { if (!\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(getContext()); mItemsAdapter.notifyDataSetChanged(m  ⁇   ⁇ \n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch =readChar(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (59, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqaC_JGWIvpp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}