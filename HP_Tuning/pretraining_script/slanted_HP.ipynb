{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "slanted_HP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugT1qQ0XEW8U"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1MRzBLtex2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e4f89c-99ae-4d4d-d343-53d9c0c50b4a"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "!pip install -qU t5\n",
        "\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_block_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "!pip install tensorflow-gcs-config==2.6.0 #2.7.0 is broken\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "     |████████████████████████████████| 153 kB 5.4 MB/s            \n",
            "     |████████████████████████████████| 286 kB 79.4 MB/s            \n",
            "     |████████████████████████████████| 1.2 MB 66.9 MB/s            \n",
            "     |████████████████████████████████| 90 kB 7.9 MB/s             \n",
            "     |████████████████████████████████| 3.1 MB 67.4 MB/s            \n",
            "     |████████████████████████████████| 366 kB 82.4 MB/s            \n",
            "     |████████████████████████████████| 4.4 MB 70.0 MB/s            \n",
            "     |████████████████████████████████| 4.0 MB 49.5 MB/s            \n",
            "     |████████████████████████████████| 59 kB 7.4 MB/s             \n",
            "     |████████████████████████████████| 596 kB 75.6 MB/s            \n",
            "     |████████████████████████████████| 895 kB 71.2 MB/s            \n",
            "     |████████████████████████████████| 3.3 MB 60.4 MB/s            \n",
            "     |████████████████████████████████| 458.3 MB 10 kB/s              \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "     |████████████████████████████████| 5.6 MB 60.7 MB/s            \n",
            "     |████████████████████████████████| 1.3 MB 65.1 MB/s            \n",
            "     |████████████████████████████████| 462 kB 78.5 MB/s            \n",
            "\u001b[?25h  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorflow-gcs-config==2.6.0\n",
            "  Downloading tensorflow_gcs_config-2.6.0-py3-none-any.whl (346 kB)\n",
            "     |████████████████████████████████| 346 kB 5.4 MB/s            \n",
            "\u001b[?25hInstalling collected packages: tensorflow-gcs-config\n",
            "  Attempting uninstall: tensorflow-gcs-config\n",
            "    Found existing installation: tensorflow-gcs-config 2.7.0\n",
            "    Uninstalling tensorflow-gcs-config-2.7.0:\n",
            "      Successfully uninstalled tensorflow-gcs-config-2.7.0\n",
            "Successfully installed tensorflow-gcs-config-2.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.73.7.82:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poax9QWkEeMV"
      },
      "source": [
        "### Loading of the tsv files\n",
        "We loaded the tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "\n",
        "nq_tsv_path = {\n",
        "    \"train\":      'gs://bucket_block_completion/dataset_08_07/train.tsv',\n",
        "    \"validation\": 'gs://bucket_block_completion/dataset_08_07/eval.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples = dict(train=1197310, validation=15783)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Y8Tje7FiNi"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WK7uMr3zYuQ"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_block_completion/code.model'\n",
        "vocab_path = 'gs://bucket_block_completion/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP4yvsTe4oAH"
      },
      "source": [
        "## If you have more than one task you have to use the prefix, otherwise it is not mandatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGp5FiN1yFQ",
        "outputId": "3738e4f2-eacd-4148-d6ea-62d1539642b7"
      },
      "source": [
        "prefix=''\n",
        "\n",
        "def nq_dataset_task(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_task(\"train\").take(5)):\n",
        "    print(ex)\n",
        "\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join([prefix + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label}\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "      \n",
        "t5.data.TaskRegistry.remove('finetuning')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"finetuning\",\n",
        "    dataset_fn=nq_dataset_task,\n",
        "    splits=[\"train\",\"validation\"],\n",
        "    text_preprocessor=preprocessing,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'public static void saveBitmapToDevice(Bitmap btmp, String filePath, String imageName) { File file = new File (filePath, imageName); if (file.exists ()) file.delete (); try <extra_id_0> catch (Exception e) { e.printStackTrace(); } }', 'output': b'{ FileOutputStream out = new FileOutputStream(file); btmp.compress(Bitmap.CompressFormat.JPEG, 90, out); out.flush(); out.close(); }'}\n",
            "{'input': b'@Override public Dampening updateGroupDampening(String tenantId, Dampening groupDampening) throws Exception { if (isEmpty(tenantId)) { throw new IllegalArgumentException(\"TenantId must be not null\"); } if (isEmpty(groupDampening)) { throw new IllegalArgumentException(\"DampeningId and TriggerId must be not null\"); } try { deferNotifications(); checkTenantId(tenantId, groupDampening); String groupId = groupDampening.getTriggerId(); Trigger groupTrigger = getTrigger(tenantId, groupId); if (!groupTrigger.isGroup()) { throw new IllegalArgumentException( \"Trigger [\" + tenantId + \"/\" + groupId + \"] is not a group trigger.\"); } Collection<Trigger> memberTriggers = getMemberTriggers(tenantId, groupId, false); for (Trigger member : memberTriggers) <extra_id_0> groupDampening.setTriggerId(groupTrigger.getId()); return updateDampening(groupDampening); } finally { releaseNotifications(); } }', 'output': b'{ groupDampening.setTriggerId(member.getId()); updateDampening(groupDampening); }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) <extra_id_0> return rv.toString(); } return toXMLString(); }', 'output': b'{ XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) { XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); } }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) { XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) <extra_id_0> } return rv.toString(); } return toXMLString(); }', 'output': b'{ XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); }'}\n",
            "{'input': b'private void getClassAnnotationsFromDTO(Object config, DTODescription description) <extra_id_0>', 'output': b'{ Annotation[] declaredAnnotations = getTemplateClass(config).getDeclaredAnnotations(); if (declaredAnnotations != null) { for (Annotation annotation : declaredAnnotations) { description.addAnnotation(annotation); } } }'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7facb9e74690>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-GatnV2dLG",
        "outputId": "f33fb64a-4fce-457c-eb52-4639f68a6763"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"finetuning\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'public List<Task> getLocationBasedTasksAssociatedWithPlace(int placeId, int geofenceTransition) throws CouldNotGetDataException { List<Task> tasks = new ArrayList<>(); SQLiteDatabase db = mDatabaseHelper.getReadableDatabase(); Cursor cursor = null; switch (geofenceTransition) { case -1: cursor = db.query(RemindyContract.LocationBasedReminderTable.TABLE_NAME, null, RemindyContract.LocationBasedReminderTable.COLUMN_NAME_PLACE_FK.getName() + \"=?\", new String[] {String.valueOf(placeId)}, null, null, null); break; case Geofence.GEOFENCE_TRANSITION_DWELL: case Geofence.GEOFENCE_TRANSITION_ENTER: cursor = db.query(RemindyContract.LocationBasedReminderTable.TABLE_NAME, null, RemindyContract.LocationBasedReminderTable.COLUMN_NAME_PLACE_FK.getName() + \"=? AND \" + RemindyContract.LocationBasedReminderTable.COLUMN_NAME_TRIGGER_ENTERING.getName() + \"=?\", new String[] {String.valueOf(placeId), \"true\"}, null, null, null); break; case Geofence.GEOFENCE_TRANSITION_EXIT: cursor = db.query(RemindyContract.LocationBasedReminderTable.TABLE_NAME, null, RemindyContract.LocationBasedReminderTable.COLUMN_NAME_PLACE_FK.getName() + \"=? AND \" + RemindyContract.LocationBasedReminderTable.COLUMN_NAME_TRIGGER_EXITING.getName() + \"=?\", new String[] {String.valueOf(placeId), \"true\"}, null, null, null); break; } if(cursor != null) { try <extra_id_0> finally { cursor.close(); } } return tasks; }', 'inputs': array([   12,    85,    25,   389,    29,  8338,  2992,  1846, 11436,\n",
            "         278,  2989,     5,    53,  3649,    68,     9,    35,  5736,\n",
            "       17644,  2092,     8,    42,     3, 19918,   749, 14923,     7,\n",
            "          85,    25,   389,    29,  3891,    11,    24,   173,   447,\n",
            "         275,     2,  3250,   764,    11,    54,  6413,     4,    33,\n",
            "       19412,    18,  2406,  1073,    11,    30,    13,   695,    17,\n",
            "        5515, 17644,  2092,     8,     7,   234,  2009,    56,  1073,\n",
            "          11,   764,     4,   584,     5,  1319,   769,  8921,  3002,\n",
            "           4,   331,  2992,  6582,   334,     4,  1824,    15,   343,\n",
            "           9,    30,     9,  5194,   769,  8921,  3002,     4,   331,\n",
            "        2992,  6582,   334,     4,  2268,    15,   343,    15, 18151,\n",
            "          15, 20631,     4,   154,    16,    34,  8670,     2,    43,\n",
            "          24,    26,    61,     7,    31,     4,   510,     5,  4652,\n",
            "          68,     8,  2847,    30,     9,    30,     9,    30,    10,\n",
            "         591,    13,   234,  5848, 17644,     4,   689,  5505, 15143,\n",
            "          15, 13963,    15,   228,   669, 12974,    56,   234,  5848,\n",
            "       17644,     4,   689,  5505, 15143,    15, 13963,    15, 11090,\n",
            "          56,  1073,    11,   764,     4,   584,     5,  1319,   769,\n",
            "        8921,  3002,     4,   331,  2992,  6582,   334,     4,  1824,\n",
            "          15,   343,     9,    30,     9,  5194,   769,  8921,  3002,\n",
            "           4,   331,  2992,  6582,   334,     4,  2268,    15,   343,\n",
            "          15, 18151,    15, 20631,     4,   154,    16,    34,  8670,\n",
            "           2,  4802,    32,    34,  5194,   769,  8921,  3002,     4,\n",
            "         331,  2992,  6582,   334,     4,  2268,    15,   343,    15,\n",
            "       12464,    15, 11090,  1254,     4,   154,    16,    34,  8670,\n",
            "           2,    43,    24,    26,    61,     7,    31,     4,   510,\n",
            "           5,  4652,    68,     8,     9,    32,   225,  6107,    30,\n",
            "           9,    30,     9,    30,    10,   591,    13,   234,  5848,\n",
            "       17644,     4,   689,  5505, 15143,    15, 13963,    15,   146,\n",
            "           2,  2643,    56,  1073,    11,   764,     4,   584,     5,\n",
            "        1319,   769,  8921,  3002,     4,   331,  2992,  6582,   334,\n",
            "           4,  1824,    15,   343,     9,    30,     9,  5194,   769,\n",
            "        8921,  3002,     4,   331,  2992,  6582,   334,     4,  2268,\n",
            "          15,   343,    15, 18151,    15, 20631,     4,   154,    16,\n",
            "          34,  8670,     2,  4802,    32,    34,  5194,   769,  8921,\n",
            "        3002,     4,   331,  2992,  6582,   334,     4,  2268,    15,\n",
            "         343,    15, 12464,    15,   146,     2,  2643,  1254,     4,\n",
            "         154,    16,    34,  8670,     2,    43,    24,    26,    61,\n",
            "           7,    31,     4,   510,     5,  4652,    68,     8,     9,\n",
            "          32,   225,  6107,    30,     9,    30,     9,    30,    10,\n",
            "         591,    13,     6,    21,     5,  1905,    49,    30,     8,\n",
            "           7,    93, 32099,   658,     7,  1073,     4,   363,    18,\n",
            "           6,     6,    14,  3891,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ while (cursor.moveToNext()) { int taskId = cursor.getInt(cursor.getColumnIndex(RemindyContract.LocationBasedReminderTable.COLUMN_NAME_TASK_FK.getName())); Task task = getTask(taskId); if(task.getStatus().equals(TaskStatus.PROGRAMMED)) tasks.add(task); } }', 'targets': array([    7,   317,    17,  1905,     4,  9074,    60,     7,    35,\n",
            "        6851,    11,  1073,     4,  1320,     5,  1905,     4,  5601,\n",
            "           5,  1319,   769,  8921,  3002,     4,   331,  2992,  6582,\n",
            "         334,     4,  2268,    15,   343,    15,  4214,    15, 20631,\n",
            "           4,   154,   366,  2881,   845,    11, 11857,     5,  8314,\n",
            "          10,    21,     5,  1435,     4,  2172,    37,   117,     5,\n",
            "       15204,     4, 15570,   491,  1011,     8,     8,  3891,     4,\n",
            "          67,     5,  1435,    10,     6,     6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public Object visit(ASTNotExpression node, Object data) <extra_id_0>', 'inputs': array([   12,   102,   654,     5,  2647,   801,   378,   248,     9,\n",
            "         102,   156,     8, 32099,     1], dtype=int32), 'targets_pretokenized': b'{ Object left = node.jjtGetChild(0).jjtAccept(this, data); if (node.getType() == SMARTSParserConstants.NOT) { return LogicalOperatorAtom.not((IQueryAtom) left); } return left; }', 'targets': array([    7,   102,  1099,    11,   248,     4, 13442,  1789, 18068,\n",
            "        3071,     5,    75,     9,   156,    10,    21,    17,   391,\n",
            "           4,   639,    16,    40,     3, 23815,   113,   519,   357,\n",
            "           4,  1439,     8,     7,    14,     3, 27221,  4931,     4,\n",
            "        1536,     5,     5,   183,     2,   179,  4931,     8,  1099,\n",
            "          10,     6,    14,  1099,    13,     6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public void cancelAll(final Object tag) { if (tag == null) { throw new IllegalArgumentException(\"Cannot cancelAll with a null tag\"); } cancelAll(new RequestFilter() <extra_id_0>); }', 'inputs': array([   12,    20,     3, 23378,     5,    64,   102,   691,     8,\n",
            "           7,    21,    17,   985,    40,    30,     8,     7,    78,\n",
            "          24,   381,    38,    28,  1657,     3, 23378,   273,   107,\n",
            "          30,   691,    46,     6,     3, 23378,     5,    74,     3,\n",
            "         125,   251,    16, 32099,    10,     6,     1], dtype=int32), 'targets_pretokenized': b'{ @Override public boolean apply(Request<?> request) { return request.getTag() == tag; } }', 'targets': array([   7,   19,   27,   12,   45, 1036,    5,  125,   25,    2,   29,\n",
            "        190,    8,    7,   14,  190,    4, 3718,   16,   40,  691,   13,\n",
            "          6,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public static boolean haveCommonElement(int[] arra, int[] arrb, int bcount) { for (int i = 0; i < arra.length; i++) <extra_id_0> return false; }', 'inputs': array([   12,    48,    45,   781,  2353,   177,     5,    53,    61,\n",
            "        3971,   184,     9,    35,    61,  3971,   214,     9,    35,\n",
            "         238,   805,     8,     7,    50,    17,    53,    65,    11,\n",
            "         116,    65,   136,  3971,   184,     4,   105,    13,    65,\n",
            "         227, 32099,    14,    76,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ int c = arra[i]; for (int j = 0; j < bcount; j++) { if (c == arrb[j]) { return true; } } }', 'targets': array([   7,   35,  202,   11, 3971,  184,   95,   86,  354,   50,   17,\n",
            "         53,  586,   11,  116,  586,  136,  238,  805,   13,  586,  227,\n",
            "          7,   21,   17,  167,   40, 3971,  214,   95,  523,  194,    8,\n",
            "          7,   14,   89,   13,    6,    6,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public static void moveEditingComponentBack() { if (editingComponent instanceof BFVViewComponent) { editingViewPage.getViewComponents().remove(editingComponent); editingViewPage.addViewComponentBack((BFVViewComponent) editingComponent); } if (editingComponent instanceof BFVMapOverlay) <extra_id_0> }', 'inputs': array([   12,    48,    20,  2525,  8308,   405,  2587,    16,     7,\n",
            "          21,    17,  1769,   150,   405,   166,  1468,   216,   380,\n",
            "         143,   405,     8,     7, 21399,   143,   410,     4,  4883,\n",
            "        2599,    37,   252,     5,  1769,   150,   405,    10, 21399,\n",
            "         143,   410,     4,  9771,   405,  2587,     5,     5,   285,\n",
            "         216,   380,   143,   405,     8, 21399,   405,    10,     6,\n",
            "          21,    17,  1769,   150,   405,   166,  1468,   216,   380,\n",
            "         100,  2274,     8, 32099,     6,     1], dtype=int32), 'targets_pretokenized': b'{ editingViewPage.getMapOverlays().remove(editingComponent); editingViewPage.addMapOverlayBack((BFVMapOverlay) editingComponent); }', 'targets': array([    7, 21399,   143,   410,     4,  7385,  2274,    22,    37,\n",
            "         252,     5,  1769,   150,   405,    10, 21399,   143,   410,\n",
            "           4,    67,   100,  2274,  2587,     5,     5,   285,   216,\n",
            "         380,   100,  2274,     8, 21399,   405,    10,     6,     1],\n",
            "      dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkLJ-FpDF8CD"
      },
      "source": [
        "### Hyper Parameter tuning\n",
        "You can run the HP tuning using the following cells.  \n",
        "Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in), *PATH_GIN_FILE* (the gin file configuration for this HP tuning) and *PRETRAINED_DIR* (the folder that contains the pretrained model).  \n",
        "**Keep attention** to change the *pretrained_model_dir* in finetune step (if you are starting the HP tuning from scratch you have to set the value *PRETRAINED_DIR*, if you are restarting the HP tuning from a previous saved checkpoint you have to set the value *MODEL_DIR*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1a1TxFNKmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ce2206-ae4b-45f3-9fa9-c70d717efb45"
      },
      "source": [
        "## this is useful if you have more than one task\n",
        "# def _rate_num_input_examples(task):\n",
        "#   if \"train\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"train\"))\n",
        "#   elif \"validation\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"validation\"))\n",
        "#   else:\n",
        "#     raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "# t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "# t5.data.MixtureRegistry.add(\n",
        "#     \"all_tasks\",\n",
        "#     [\"java_construct\", \"java_token\", \"java_block\", \"android_construct\", \"android_token\", \"android_block\"],\n",
        "#     default_rate=_rate_num_input_examples\n",
        "#      #default_rate=1.0\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.seqio.dataset_providers.Mixture at 0x7f4a4465d470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular\n",
        "\n",
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/HP_TUNING/slanted/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = slanted_triangular,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oHp5ScE7nf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bd86ff-c43f-470b-98aa-939289fbb0a5"
      },
      "source": [
        "PATH_GIN_FILE = 'gs://bucket_block_completion/HP_TUNING/slanted/operative_config.gin'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 50000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"finetuning\",\n",
        "        pretrained_model_dir=PRETRAINED_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/HP_TUNING/slanted/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/HP_TUNING/slanted/operative_config.gin\n",
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/pretrained_model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/pretrained_model/operative_config.gin\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/HP_TUNING/slanted/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.7.82:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.7.82:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.7.82:8470', '_evaluation_master': 'grpc://10.73.7.82:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7faa73c16150>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.7.82:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.7.82:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -351142815347699484)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4783648215290353547)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6018770272977275086)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -2321091585663417253)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 527400030890175954)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 2648463850517493043)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -8062179659450263366)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 740380811639149528)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4828739333839253789)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 5432926450839577107)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3043731233229512421)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('vocab', 'model'), ('experts', 'batch'), ('ensemble', 'ensemble'), ('d_ff', 'model'), ('batch', 'batch'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7faa6f7b4ed0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 6.85e+08\n",
            " allreduce/[0]: 6.85e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 2.01e+08\n",
            "einsum: 4.06e+13\n",
            "einsum_unique: 4.05e+13\n",
            "output: 3.66e+11\n",
            " output/AddOperation: 6.7e+10\n",
            " output/BinaryOpWithBroadcasting: 4.51e+09\n",
            " output/BroadcastOperation: 2.02e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 1.46e+11\n",
            " output/ImportOperation: 6.29e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 1.34e+10\n",
            " output/RandomOperation: 2.96e+07\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 7.93e+09\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.39e+08\n",
            " output/ScalarMultiplyOperation: 3.64e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 7.48e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 1.39e+10\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 3.58e+11\n",
            " output_unique/AddOperation: 6.67e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.47e+09\n",
            " output_unique/BroadcastOperation: 2.02e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 1.42e+11\n",
            " output_unique/ImportOperation: 7.87e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 1.27e+10\n",
            " output_unique/RandomOperation: 2.96e+07\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 7.76e+09\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 7.1e+07\n",
            " output_unique/ScalarMultiplyOperation: 3.55e+09\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 7.25e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 1.39e+10\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://bucket_block_completion/pretrained_model/model.ckpt-200000:\n",
            "INFO:tensorflow:Variables in gs://bucket_block_completion/pretrained_model/model.ckpt-200000 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://bucket_block_completion/pretrained_model/model.ckpt-200000:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:758: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 200000...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 200000 into gs://bucket_block_completion/HP_TUNING/slanted/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 200000...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 96)\n",
            "INFO:tensorflow:loss = 0.6796875, step = 200100\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 90)\n",
            "INFO:tensorflow:loss = 0.5546875, step = 200200 (63.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5741\n",
            "INFO:tensorflow:examples/sec: 402.969\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CviTb69IJUQ_"
      },
      "source": [
        "### Evaluate the performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJYVynoR5hDe"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 512\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"finetuning\",\n",
        "    # mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1 #evaluate only last checkpoint\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}