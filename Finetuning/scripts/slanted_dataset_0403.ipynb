{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "slanted_dataset_0403.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugT1qQ0XEW8U"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "39f5adc8-1cee-4e4a-ad3f-ceb679d468f8"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "!pip install -qU t5\n",
        "\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_block_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "!pip install tensorflow-gcs-config #2.7.0 is broken\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "     |████████████████████████████████| 153 kB 5.3 MB/s            \n",
            "     |████████████████████████████████| 286 kB 36.5 MB/s            \n",
            "     |████████████████████████████████| 1.2 MB 46.8 MB/s            \n",
            "     |████████████████████████████████| 4.9 MB 66.2 MB/s            \n",
            "     |████████████████████████████████| 4.0 MB 42.6 MB/s            \n",
            "     |████████████████████████████████| 3.1 MB 29.1 MB/s            \n",
            "     |████████████████████████████████| 366 kB 56.3 MB/s            \n",
            "     |████████████████████████████████| 90 kB 7.6 MB/s             \n",
            "     |████████████████████████████████| 596 kB 40.1 MB/s            \n",
            "     |████████████████████████████████| 3.3 MB 28.5 MB/s            \n",
            "     |████████████████████████████████| 59 kB 5.9 MB/s             \n",
            "     |████████████████████████████████| 895 kB 65.6 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-gcs-config in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.57.246.74:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poax9QWkEeMV"
      },
      "source": [
        "### Loading of the tsv files\n",
        "We loaded the tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "\n",
        "nq_tsv_path = {\n",
        "    \"train\":      'gs://bucket_block_completion/dataset_04_03/train.tsv',\n",
        "    \"validation\": 'gs://bucket_block_completion/dataset_04_03/test.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples = dict(train=703252, validation=15742)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Y8Tje7FiNi"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WK7uMr3zYuQ"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_block_completion/code.model'\n",
        "vocab_path = 'gs://bucket_block_completion/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP4yvsTe4oAH"
      },
      "source": [
        "## If you have more than one task you have to use the prefix, otherwise it is not mandatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGp5FiN1yFQ",
        "outputId": "716ab68a-f70c-46c0-a621-b32efbe92c42"
      },
      "source": [
        "prefix=''\n",
        "\n",
        "def nq_dataset_task(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_task(\"train\").take(5)):\n",
        "    print(ex)\n",
        "\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join([prefix + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label}\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "      \n",
        "t5.data.TaskRegistry.remove('finetuning')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"finetuning\",\n",
        "    dataset_fn=nq_dataset_task,\n",
        "    splits=[\"train\",\"validation\"],\n",
        "    text_preprocessor=preprocessing,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw train examples...\n",
            "{'input': b\"@Override public void keyTyped(KeyEvent e) { if( e.getKeyChar() == 'w' ) { transform.T.y -= pixelToUnit/scale; } else if( e.getKeyChar() == 's' ) { transform.T.y += pixelToUnit/scale; } else if( e.getKeyChar() == 'a' ) { transform.T.x += pixelToUnit/scale; } else if( e.getKeyChar() == 'd' ) { transform.T.x -= pixelToUnit/scale; } else if( e.getKeyChar() == 'q' ) { scale *= 1.05; } else if( e.getKeyChar() == 'e' ) { scale *= 0.95; } else if( e.getKeyChar() == 'h' ) <extra_id_0> if( scale < 0.001 ) scale = 0.001; else if( scale > 1000 ) scale = 1000; repaint(); }\", 'output': b'{ transform.reset(); scale = 1; }'}\n",
            "{'input': b'public byte[] toBytes() throws IOException <extra_id_0>', 'output': b'{ ByteArrayOutputStream out = new ByteArrayOutputStream(); out.write(0xef); ByteHelper.write8ByteUnsignedIntLittleEndian(binlogPosition, out); if (StringUtils.isNotEmpty(binlogFileName)) { out.write(binlogFileName.getBytes()); } return out.toByteArray(); }'}\n",
            "{'input': b'private Element createElement(final String name) <extra_id_0>', 'output': b'{ final String[] parts = NAMESPACE_DELIMITER.split(name); if (parts.length == 2) { return new Element(parts[1], getNamespace(parts[0])); } return new Element(name); }'}\n",
            "{'input': b'public void endTest(Test test) { try <extra_id_0> catch (IOException e) { Log.e(LOG_TAG, safeMessage(e)); } }', 'output': b'{ if (test instanceof TestCase) { recordTestTime(); mSerializer.endTag(\"\", TAG_CASE); mSerializer.flush(); } }'}\n",
            "{'input': b'public void endTest(Test test) { try { if (test instanceof TestCase) <extra_id_0> } catch (IOException e) { Log.e(LOG_TAG, safeMessage(e)); } }', 'output': b'{ recordTestTime(); mSerializer.endTag(\"\", TAG_CASE); mSerializer.flush(); }'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f833f5512d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-GatnV2dLG",
        "outputId": "34d5871e-ba4d-490b-d9d8-f0e587a7013c"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"finetuning\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'public ExceptionResponse getExceptions( ExceptionRequest request) { synchronized (CacheCore.class) { List<ExceptionDatum> response = new ArrayList<>(); Map<String, Set<String>> componentNameInstanceId = request.getComponentNameInstanceId(); Set<String> componentNameFilter; if (componentNameInstanceId == null) { componentNameFilter = idxComponentInstance.keySet(); } else { componentNameFilter = componentNameInstanceId.keySet(); } for (String componentName : componentNameFilter) { Set<String> instanceIdFilter; if (componentNameInstanceId == null || componentNameInstanceId.get(componentName) == null) { instanceIdFilter = idxComponentInstance.get(componentName).keySet(); } else { instanceIdFilter = componentNameInstanceId.get(componentName); } for (String instanceId : instanceIdFilter) <extra_id_0> } return new ExceptionResponse(response); } }', 'inputs': array([   12,   172,   164,    41,    38,    22,     5,   172,   125,\n",
            "         190,     8,     7,   310,    17,   307,  1760,     4,    88,\n",
            "           8,     7,    85,    25,    38,  4147,    29,   250,    11,\n",
            "          24,   173,   447,   188,    25,    31,     9,   300,    25,\n",
            "          31,   243, 10064,  4784,    11,   190,     4, 19994,  4784,\n",
            "          18,   300,    25,    31,    29, 10064,   251,    13,    21,\n",
            "          17, 13694,  4784,    40,    30,     8,     7, 10064,   251,\n",
            "          11,  2747,   405,   316,     4,  1208,    18,     6,    77,\n",
            "           7, 10064,   251,    11, 10064,  4784,     4,  1208,    18,\n",
            "           6,    50,    17,    31, 10064,    58, 10064,   251,     8,\n",
            "           7,   300,    25,    31,    29,  6309,   251,    13,    21,\n",
            "          17, 13694,  4784,    40,    30,     3,     2, 10064,  4784,\n",
            "           4,    33,     5, 13694,     8,    40,    30,     8,     7,\n",
            "        6309,   251,    11,  2747,   405,   316,     4,    33,     5,\n",
            "       13694,     8,     4,  1208,    18,     6,    77,     7,  6309,\n",
            "         251,    11, 10064,  4784,     4,    33,     5, 13694,    10,\n",
            "           6,    50,    17,    31,  6309,    58,  6309,   251,     8,\n",
            "       32099,     6,    14,    24,   172,   164,     5,   762,    10,\n",
            "           6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ int idx = idxComponentInstance.get(componentName).get(instanceId); for (ExceptionDatapoint exceptionDatapoint : cacheException.get(idx)) { response.add(new ExceptionDatum(componentName, instanceId, exceptionDatapoint)); } }', 'targets': array([    7,    35,  2747,    11,  2747,   405,   316,     4,    33,\n",
            "           5, 13694,     8,     4,    33,     5,  8585,    10,    50,\n",
            "          17,    38,    99,  2303,   733,    99,  2303,    58,   831,\n",
            "          38,     4,    33,     5,  2429,     8,     8,     7,   250,\n",
            "           4,    67,     5,    74,   172,  4147,     5, 13694,     9,\n",
            "        6309,     9,   733,    99,  2303,    79,     6,     6,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b\"protected List<String> trim(List<String> comments) { List<String> trimComments = new ArrayList<>(); int n = 0; boolean tryRemoveWhitespace = true; while (tryRemoveWhitespace) { boolean allLinesAreShorter = true; for (String comment : comments) { if (comment.length() <= n) { continue; } if (comment.charAt(n) != ' ') { tryRemoveWhitespace = false; } allLinesAreShorter = false; } if (allLinesAreShorter) { break; } if (tryRemoveWhitespace) { n++; } } for (String comment : comments) <extra_id_0> return trimComments; }\", 'inputs': array([   73,    85,    25,    31,    29,  9288,     5,    71,    25,\n",
            "          31,    29,  7511,     8,     7,    85,    25,    31,    29,\n",
            "        9288,  3672,    11,    24,   173,   447,    35,   446,    11,\n",
            "         116,    45,    93,  1616,  7168,    11,    89,    13,   317,\n",
            "          17,  4844,  1616,  7168,     8,     7,    45,   506,   481,\n",
            "        8348,  1917,   239,    11,    89,    13,    50,    17,    31,\n",
            "        2131,    58,  7511,     8,     7,    21,    17,  3095,     4,\n",
            "         105,    16,   685,   446,     8,     7,  1584,    13,     6,\n",
            "          21,    17,  3095,     4,  1586,     5,   127,     8,    49,\n",
            "           3,     2,     3,     2,     8,     7,    93,  1616,  7168,\n",
            "          11,    76,    13,     6,   506,   481,  8348,  1917,   239,\n",
            "          11,    76,    13,     6,    21,    17,  1241,   481,  8348,\n",
            "        1917,   239,     8,     7,   591,    13,     6,    21,    17,\n",
            "        4844,  1616,  7168,     8,     7,   446,   854,     6,     6,\n",
            "          50,    17,    31,  2131,    58,  7511,     8, 32099,    14,\n",
            "        9288,  3672,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ if (comment.length() > n) { String substring = comment.substring(n); trimComments.add(substring); } else { trimComments.add(\"\"); } }', 'targets': array([   7,   21,   17, 3095,    4,  105,   16,    3,   29,  446,    8,\n",
            "          7,   26,    3,  633,   11, 2131,    4,  633,    5,  127,   10,\n",
            "       9288, 3672,    4,   67,    5,  633,   10,    6,   77,    7, 9288,\n",
            "       3672,    4,   67, 3912,    6,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public static void setNextAlert(final Context context) { ScheduleRecord next = getNextSchedule(); AlarmManager am = (AlarmManager)context.getSystemService(Context.ALARM_SERVICE); Intent intent = new Intent(context, AlarmReceiver.class); if (next == null) <extra_id_0> intent.putExtra(\"brightness\", next.getBrightness()); PendingIntent sender = PendingIntent.getBroadcast(context, 0, intent, PendingIntent.FLAG_CANCEL_CURRENT); long time = getTimeInMillis(next); am.set(AlarmManager.RTC, time, sender); Calendar c = Calendar.getInstance(); c.setTimeInMillis(System.currentTimeMillis()); long time2 = time - c.getTimeInMillis(); time2 /= 1000; long s = time2 % 60; time2 /= 60; long m = time2 % 60; time2 /= 60; long h = time2 % 24; Log.v(LOG_NAME, \"Next schedule from now: \"+h+\":\"+m+\":\"+s); }', 'inputs': array([   12,    48,    20, 16911,  2568,     5,    64,     3,    92,\n",
            "         130,     8,     7, 15452,   504,   574,    11,  3712,  2418,\n",
            "          18,     3, 10710,  7335,    11,    17, 10710,     8,   201,\n",
            "           4,  2685,     5,    92,     4, 10148,    15,  1455,    10,\n",
            "         604,   576,    11,    24,   604,     5,   201,     9, 12454,\n",
            "        1550,     4,    88,    10,    21,    17,   395,    40,    30,\n",
            "           8, 32099,   576,     4,  1791,    28, 15877,    43,   574,\n",
            "           4,    33,  8993,    39,  6479,  1291,    11,  6479,     4,\n",
            "       16334,     5,   201,     9,   312,   576,     9,  6479,     4,\n",
            "        2090,    15,  8727,    15,  5509,    10,   126,   546,    11,\n",
            "           3, 11910,     5,   395,    10,  7335,     4,    63,     5,\n",
            "       10710,     4, 22144,     9,   546,     9,  1291,    10,  1777,\n",
            "         202,    11,  1777,     4,   351,    18,   202,     4, 24172,\n",
            "           5,   473,     4,   167,  1167,    39,   126,   546,    80,\n",
            "          11,   546,   139,   202,     4, 11910,    18,   546,    80,\n",
            "         260,   161,  2962,    13,   126,     3,    22,    11,   546,\n",
            "          80,     3,     2,     3,     2,  2986,   546,    80,   260,\n",
            "         161,     3,     2,  2986,   126,    54,    11,   546,    80,\n",
            "           3,     2,     3,     2,  2986,   546,    80,   260,   161,\n",
            "           3,     2,  2986,   126,   827,    11,   546,    80,     3,\n",
            "           2,   804,     2,    13,   319,     4,   291,     5,  1192,\n",
            "          15,   343,     9,    32,  1303,  3382,   255,  1426,    56,\n",
            "        1113,   773, 21149,    87, 21149,    22,    10,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'{ PendingIntent sender = PendingIntent.getBroadcast(context, 0, intent, 0); am.cancel(sender); Log.d(LOG_NAME, \"Cancel pending alarm\"); return; }', 'targets': array([    7,  6479,  1291,    11,  6479,     4, 16334,     5,   201,\n",
            "           9,   312,   576,     9,   522,  7335,     4,  1753,     5,\n",
            "        2129,    10,   319,     4,   101,     5,  1192,    15,   343,\n",
            "           9,    32,  3074,  3332,  5178,    46,    14,    13,     6,\n",
            "           1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'private void updateDateTimeDisplay(){ Button btn; String ampm; int hour; if(mHour > 12) <extra_id_0> else { ampm = \"am\"; hour = mHour; } btn = (Button) findViewById(R.id.planner_btnTimeChange); btn.setText(new StringBuilder() .append(hour) .append(\":\") .append(pad(mMin)) .append(\" \") .append(ampm)); btn = (Button) findViewById(R.id.planner_btnDateChange); btn.setText(new StringBuilder() .append(mMonth+1) .append(\"/\") .append(mDay) .append(\"/\") .append(mYear)); }', 'inputs': array([   47,    20,   233,  1751,  1157,   814,     3,   448,  7805,\n",
            "          13,    26,     3,  7171,    87,    13,    35,  7958,    13,\n",
            "          21,     5,    87,  5705,     3,    29,  2561,     8, 32099,\n",
            "          77,     7,     3,  7171,    87,    11,    32,  2878,   187,\n",
            "        7958,    11,    54,  5705,    13,     6,  7805,    11,    17,\n",
            "         448,     8,  3510,     5,   144,     4,   111,     4, 31434,\n",
            "          15,  6692,   199,   704,    10,  7805,     4,   811,     5,\n",
            "          74,   375,    16,     3,     4,   109,     5, 12201,     8,\n",
            "           3,     4,   109, 11521,     3,     4,   109,     5,  6321,\n",
            "           5,    87,  1562,     8,     8,     3,     4,   109,    28,\n",
            "          32,     8,     3,     4,   109,     5,  7171,    87,    79,\n",
            "        7805,    11,    17,   448,     8,  3510,     5,   144,     4,\n",
            "         111,     4, 31434,    15,  6692,   267,   704,    10,  7805,\n",
            "           4,   811,     5,    74,   375,    16,     3,     4,   109,\n",
            "           5,    87,  3758, 14401,     3,     4,   109,  6206,     3,\n",
            "           4,   109,     5,    87,  2218,     8,     3,     4,   109,\n",
            "        6206,     3,     4,   109,     5,    87,     2,  1300,    79,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'{ ampm = \"pm\"; hour = mHour - 12; }', 'targets': array([   7,    3, 7171,   87,   11,   32, 6437,  187, 7958,   11,   54,\n",
            "       5705,  139, 2561,   13,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'@Override public Token<?> getDelegationToken(String renewer) throws IOException <extra_id_0>', 'inputs': array([   19,    27,    12,  3014,    25,     2,    29,    41, 24633,\n",
            "           5,    31,   893,    74,   239,     8,    42,   115, 32099,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'{ logger.atFine().log(\"GHFS.getDelegationToken: renewer: %s\", renewer); Token<?> result = null; if (delegationTokens != null) { result = delegationTokens.getBoundOrNewDT(renewer); } logger.atFine().log(\"GHFS.getDelegationToken:=> %s\", result); return result; }', 'targets': array([    7,   347,     4,  1600,   216,  5321,    37,   417,    28,\n",
            "       16137,  3404,     4,    33, 24633,    56,   893,    74,   239,\n",
            "          56,     3,     2,    22,    43,   893,    74,   239,    10,\n",
            "        3014,    25,     2,    29,    84,    11,    30,    13,    21,\n",
            "          17, 25546,  2778,    49,    30,     8,     7,    84,    11,\n",
            "           3, 25546,  2778,     4,    33,  2451, 22112,  9549,     5,\n",
            "         753,    74,   239,    10,     6,   347,     4,  1600,   216,\n",
            "        5321,    37,   417,    28, 16137,  3404,     4,    33, 24633,\n",
            "          56,   161,    29,     3,     2,    22,    43,    84,    10,\n",
            "          14,    84,    13,     6,     1], dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkLJ-FpDF8CD"
      },
      "source": [
        "### Hyper Parameter tuning\n",
        "You can run the HP tuning using the following cells.  \n",
        "Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in), *PATH_GIN_FILE* (the gin file configuration for this HP tuning) and *PRETRAINED_DIR* (the folder that contains the pretrained model).  \n",
        "**Keep attention** to change the *pretrained_model_dir* in finetune step (if you are starting the HP tuning from scratch you have to set the value *PRETRAINED_DIR*, if you are restarting the HP tuning from a previous saved checkpoint you have to set the value *MODEL_DIR*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1a1TxFNKmx"
      },
      "source": [
        "## this is useful if you have more than one task\n",
        "# def _rate_num_input_examples(task):\n",
        "#   if \"train\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"train\"))\n",
        "#   elif \"validation\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"validation\"))\n",
        "#   else:\n",
        "#     raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "# t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "# t5.data.MixtureRegistry.add(\n",
        "#     \"all_tasks\",\n",
        "#     [\"java_construct\", \"java_token\", \"java_block\", \"android_construct\", \"android_token\", \"android_block\"],\n",
        "#     default_rate=_rate_num_input_examples\n",
        "#      #default_rate=1.0\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular\n",
        "\n",
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/finetuning/0403/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 5000),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = slanted_triangular,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oHp5ScE7nf2",
        "outputId": "b03aa1ea-6600-46df-e55c-58a12f9688c1"
      },
      "source": [
        "PATH_GIN_FILE = 'gs://bucket_block_completion/finetuning/0403/operative_config_slanted.gin'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 275000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"finetuning\",\n",
        "        pretrained_model_dir=MODEL_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0403/operative_config_slanted.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0403/operative_config_slanted.gin\n",
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0403/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0403/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0403/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.57.246.74:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.57.246.74:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.57.246.74:8470', '_evaluation_master': 'grpc://10.57.246.74:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f8304bc6fd0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.57.246.74:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.57.246.74:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -7856908261367081188)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 123945143110870985)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -5916066547880921329)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -8373982537953596958)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -2920128841871868342)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1249052997183467796)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -3668896137211972573)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6507665713801399630)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -7353719664566429140)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 7665079880477263461)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -1613611490872455680)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:401: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('d_ff', 'model'), ('ensemble', 'ensemble'), ('batch', 'batch'), ('experts', 'batch'), ('heads', 'model'), ('vocab', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f83045da610>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 6.85e+08\n",
            " allreduce/[0]: 6.85e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 2.01e+08\n",
            "einsum: 4.06e+13\n",
            "einsum_unique: 4.05e+13\n",
            "output: 3.66e+11\n",
            " output/AddOperation: 6.7e+10\n",
            " output/BinaryOpWithBroadcasting: 4.51e+09\n",
            " output/BroadcastOperation: 2.02e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 1.46e+11\n",
            " output/ImportOperation: 6.29e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 1.34e+10\n",
            " output/RandomOperation: 2.96e+07\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 7.93e+09\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.39e+08\n",
            " output/ScalarMultiplyOperation: 3.64e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 7.48e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 1.39e+10\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 3.58e+11\n",
            " output_unique/AddOperation: 6.67e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.47e+09\n",
            " output_unique/BroadcastOperation: 2.02e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 1.42e+11\n",
            " output_unique/ImportOperation: 7.87e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 1.27e+10\n",
            " output_unique/RandomOperation: 2.96e+07\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 7.76e+09\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 7.1e+07\n",
            " output_unique/ScalarMultiplyOperation: 3.55e+09\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 7.25e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 1.39e+10\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://bucket_block_completion/finetuning/0403/model/model.ckpt-424400:\n",
            "INFO:tensorflow:Variables in gs://bucket_block_completion/finetuning/0403/model/model.ckpt-424400 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://bucket_block_completion/finetuning/0403/model/model.ckpt-424400:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0403/model/model.ckpt-424400\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1165: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:758: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 424400...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 424400 into gs://bucket_block_completion/finetuning/0403/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 424400...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 96)\n",
            "INFO:tensorflow:loss = 0.09765625, step = 424500\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 90)\n",
            "INFO:tensorflow:loss = 0.09472656, step = 424600 (63.501 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57485\n",
            "INFO:tensorflow:examples/sec: 403.161\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 85)\n",
            "INFO:tensorflow:loss = 0.10253906, step = 424700 (63.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.583\n",
            "INFO:tensorflow:examples/sec: 405.248\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 80)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 424800 (63.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57027\n",
            "INFO:tensorflow:examples/sec: 401.988\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 75)\n",
            "INFO:tensorflow:loss = 0.09765625, step = 424900 (63.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58287\n",
            "INFO:tensorflow:examples/sec: 405.214\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 70)\n",
            "INFO:tensorflow:loss = 0.125, step = 425000 (63.757 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56846\n",
            "INFO:tensorflow:examples/sec: 401.526\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 65)\n",
            "INFO:tensorflow:loss = 0.08935547, step = 425100 (63.692 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56997\n",
            "INFO:tensorflow:examples/sec: 401.911\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 60)\n",
            "INFO:tensorflow:loss = 0.10058594, step = 425200 (63.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5829\n",
            "INFO:tensorflow:examples/sec: 405.223\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 55)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 425300 (63.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58292\n",
            "INFO:tensorflow:examples/sec: 405.228\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 50)\n",
            "INFO:tensorflow:loss = 0.091308594, step = 425400 (63.689 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57012\n",
            "INFO:tensorflow:examples/sec: 401.95\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 45)\n",
            "INFO:tensorflow:loss = 0.08886719, step = 425500 (63.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58286\n",
            "INFO:tensorflow:examples/sec: 405.212\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 40)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 425600 (63.712 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56959\n",
            "INFO:tensorflow:examples/sec: 401.815\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (12, 35)\n",
            "INFO:tensorflow:loss = 0.09765625, step = 425700 (63.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56972\n",
            "INFO:tensorflow:examples/sec: 401.847\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 30)\n",
            "INFO:tensorflow:loss = 0.09667969, step = 425800 (63.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58286\n",
            "INFO:tensorflow:examples/sec: 405.212\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 25)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 425900 (63.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58302\n",
            "INFO:tensorflow:examples/sec: 405.253\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 20)\n",
            "INFO:tensorflow:loss = 0.09765625, step = 426000 (63.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57011\n",
            "INFO:tensorflow:examples/sec: 401.947\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (16, 15)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 426100 (63.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58297\n",
            "INFO:tensorflow:examples/sec: 405.24\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 9)\n",
            "INFO:tensorflow:loss = 0.095703125, step = 426200 (63.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56699\n",
            "INFO:tensorflow:examples/sec: 401.15\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 4)\n",
            "INFO:tensorflow:loss = 0.107421875, step = 426300 (63.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56911\n",
            "INFO:tensorflow:examples/sec: 401.692\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 96)\n",
            "INFO:tensorflow:loss = 0.09716797, step = 426400 (63.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58293\n",
            "INFO:tensorflow:examples/sec: 405.23\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 91)\n",
            "INFO:tensorflow:loss = 0.09326172, step = 426500 (63.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58301\n",
            "INFO:tensorflow:examples/sec: 405.25\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (21, 86)\n",
            "INFO:tensorflow:loss = 0.09082031, step = 426600 (63.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57059\n",
            "INFO:tensorflow:examples/sec: 402.071\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 81)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 426700 (63.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58287\n",
            "INFO:tensorflow:examples/sec: 405.214\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (23, 76)\n",
            "INFO:tensorflow:loss = 0.104003906, step = 426800 (63.678 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57039\n",
            "INFO:tensorflow:examples/sec: 402.019\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 71)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 426900 (63.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57012\n",
            "INFO:tensorflow:examples/sec: 401.951\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 66)\n",
            "INFO:tensorflow:loss = 0.10498047, step = 427000 (63.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58291\n",
            "INFO:tensorflow:examples/sec: 405.226\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (26, 61)\n",
            "INFO:tensorflow:loss = 0.09375, step = 427100 (63.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58297\n",
            "INFO:tensorflow:examples/sec: 405.241\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 56)\n",
            "INFO:tensorflow:loss = 0.08886719, step = 427200 (63.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56876\n",
            "INFO:tensorflow:examples/sec: 401.602\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (28, 51)\n",
            "INFO:tensorflow:loss = 0.09326172, step = 427300 (63.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58282\n",
            "INFO:tensorflow:examples/sec: 405.202\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 46)\n",
            "INFO:tensorflow:loss = 0.09375, step = 427400 (63.697 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56996\n",
            "INFO:tensorflow:examples/sec: 401.911\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 41)\n",
            "INFO:tensorflow:loss = 0.10253906, step = 427500 (63.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57052\n",
            "INFO:tensorflow:examples/sec: 402.053\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 36)\n",
            "INFO:tensorflow:loss = 0.10595703, step = 427600 (63.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58277\n",
            "INFO:tensorflow:examples/sec: 405.19\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (32, 31)\n",
            "INFO:tensorflow:loss = 0.09277344, step = 427700 (63.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58295\n",
            "INFO:tensorflow:examples/sec: 405.234\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (33, 26)\n",
            "INFO:tensorflow:loss = 0.10253906, step = 427800 (63.688 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57017\n",
            "INFO:tensorflow:examples/sec: 401.963\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 21)\n",
            "INFO:tensorflow:loss = 0.107421875, step = 427900 (63.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58294\n",
            "INFO:tensorflow:examples/sec: 405.232\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (35, 16)\n",
            "INFO:tensorflow:loss = 0.107421875, step = 428000 (63.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56937\n",
            "INFO:tensorflow:examples/sec: 401.759\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 11)\n",
            "INFO:tensorflow:loss = 0.08984375, step = 428100 (63.697 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56989\n",
            "INFO:tensorflow:examples/sec: 401.893\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (37, 6)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 428200 (63.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58289\n",
            "INFO:tensorflow:examples/sec: 405.221\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 1)\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 97)\n",
            "INFO:tensorflow:loss = 0.099609375, step = 428300 (63.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58246\n",
            "INFO:tensorflow:examples/sec: 405.111\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 92)\n",
            "INFO:tensorflow:loss = 0.1015625, step = 428400 (63.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56967\n",
            "INFO:tensorflow:examples/sec: 401.836\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 87)\n",
            "INFO:tensorflow:loss = 0.106933594, step = 428500 (63.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58288\n",
            "INFO:tensorflow:examples/sec: 405.217\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (41, 82)\n",
            "INFO:tensorflow:loss = 0.09326172, step = 428600 (63.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56921\n",
            "INFO:tensorflow:examples/sec: 401.718\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (42, 77)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 428700 (63.695 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56994\n",
            "INFO:tensorflow:examples/sec: 401.905\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (43, 72)\n",
            "INFO:tensorflow:loss = 0.09667969, step = 428800 (63.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58305\n",
            "INFO:tensorflow:examples/sec: 405.261\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (44, 67)\n",
            "INFO:tensorflow:loss = 0.091308594, step = 428900 (63.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58295\n",
            "INFO:tensorflow:examples/sec: 405.236\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (45, 62)\n",
            "INFO:tensorflow:loss = 0.11816406, step = 429000 (63.779 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56793\n",
            "INFO:tensorflow:examples/sec: 401.391\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (46, 57)\n",
            "INFO:tensorflow:loss = 0.09472656, step = 429100 (63.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58289\n",
            "INFO:tensorflow:examples/sec: 405.221\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (47, 52)\n",
            "INFO:tensorflow:loss = 0.084472656, step = 429200 (63.732 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5691\n",
            "INFO:tensorflow:examples/sec: 401.69\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (48, 47)\n",
            "INFO:tensorflow:loss = 0.09472656, step = 429300 (63.671 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57045\n",
            "INFO:tensorflow:examples/sec: 402.034\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 42)\n",
            "INFO:tensorflow:loss = 0.088378906, step = 429400 (63.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58299\n",
            "INFO:tensorflow:examples/sec: 405.246\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (50, 37)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 429500 (63.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5829\n",
            "INFO:tensorflow:examples/sec: 405.222\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 429500...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 429500 into gs://bucket_block_completion/finetuning/0403/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 429500...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (51, 22)\n",
            "INFO:tensorflow:loss = 0.099609375, step = 429600 (70.061 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.42735\n",
            "INFO:tensorflow:examples/sec: 365.401\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (52, 17)\n",
            "INFO:tensorflow:loss = 0.09326172, step = 429700 (63.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58302\n",
            "INFO:tensorflow:examples/sec: 405.252\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (53, 12)\n",
            "INFO:tensorflow:loss = 0.109375, step = 429800 (63.726 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56924\n",
            "INFO:tensorflow:examples/sec: 401.726\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (54, 7)\n",
            "INFO:tensorflow:loss = 0.1015625, step = 429900 (64.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.54452\n",
            "INFO:tensorflow:examples/sec: 395.397\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (55, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (55, 96)\n",
            "INFO:tensorflow:loss = 0.09765625, step = 430000 (63.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58297\n",
            "INFO:tensorflow:examples/sec: 405.241\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (56, 91)\n",
            "INFO:tensorflow:loss = 0.100097656, step = 430100 (63.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58307\n",
            "INFO:tensorflow:examples/sec: 405.265\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (57, 86)\n",
            "INFO:tensorflow:loss = 0.09716797, step = 430200 (63.688 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57016\n",
            "INFO:tensorflow:examples/sec: 401.961\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (58, 81)\n",
            "INFO:tensorflow:loss = 0.10986328, step = 430300 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.278\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (59, 76)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 430400 (63.778 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56787\n",
            "INFO:tensorflow:examples/sec: 401.374\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (60, 71)\n",
            "INFO:tensorflow:loss = 0.10253906, step = 430500 (63.730 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56915\n",
            "INFO:tensorflow:examples/sec: 401.701\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (61, 66)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 430600 (63.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58298\n",
            "INFO:tensorflow:examples/sec: 405.243\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (62, 61)\n",
            "INFO:tensorflow:loss = 0.095703125, step = 430700 (63.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58283\n",
            "INFO:tensorflow:examples/sec: 405.205\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (63, 56)\n",
            "INFO:tensorflow:loss = 0.10986328, step = 430800 (63.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57067\n",
            "INFO:tensorflow:examples/sec: 402.091\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (64, 51)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 430900 (63.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58277\n",
            "INFO:tensorflow:examples/sec: 405.189\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (65, 46)\n",
            "INFO:tensorflow:loss = 0.103515625, step = 431000 (63.696 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56994\n",
            "INFO:tensorflow:examples/sec: 401.906\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (66, 41)\n",
            "INFO:tensorflow:loss = 0.100097656, step = 431100 (63.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56925\n",
            "INFO:tensorflow:examples/sec: 401.729\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (67, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CviTb69IJUQ_"
      },
      "source": [
        "### Evaluate the performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJYVynoR5hDe"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 512\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"finetuning\",\n",
        "    # mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1 #evaluate only last checkpoint\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}