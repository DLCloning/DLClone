{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "slanted_dataset_0605.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugT1qQ0XEW8U"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "c933c79f-a050-41f6-e432-f7ad2e7c4064"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "!pip install -qU t5\n",
        "\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_block_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "!pip install tensorflow-gcs-config #2.7.0 is broken\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "     |████████████████████████████████| 153 kB 5.1 MB/s            \n",
            "     |████████████████████████████████| 366 kB 29.5 MB/s            \n",
            "     |████████████████████████████████| 90 kB 10.1 MB/s            \n",
            "     |████████████████████████████████| 3.1 MB 75.8 MB/s            \n",
            "     |████████████████████████████████| 4.9 MB 64.2 MB/s            \n",
            "     |████████████████████████████████| 286 kB 82.6 MB/s            \n",
            "     |████████████████████████████████| 1.2 MB 70.4 MB/s            \n",
            "     |████████████████████████████████| 4.0 MB 62.3 MB/s            \n",
            "     |████████████████████████████████| 596 kB 71.3 MB/s            \n",
            "     |████████████████████████████████| 895 kB 73.3 MB/s            \n",
            "     |████████████████████████████████| 3.3 MB 63.3 MB/s            \n",
            "     |████████████████████████████████| 59 kB 8.6 MB/s             \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-gcs-config in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.31.237.90:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poax9QWkEeMV"
      },
      "source": [
        "### Loading of the tsv files\n",
        "We loaded the tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "\n",
        "nq_tsv_path = {\n",
        "    \"train\":      'gs://bucket_block_completion/dataset_06_05/train.tsv',\n",
        "    \"validation\": 'gs://bucket_block_completion/dataset_06_05/test.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples = dict(train=1023430, validation=15742)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Y8Tje7FiNi"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WK7uMr3zYuQ"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_block_completion/code.model'\n",
        "vocab_path = 'gs://bucket_block_completion/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP4yvsTe4oAH"
      },
      "source": [
        "## If you have more than one task you have to use the prefix, otherwise it is not mandatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGp5FiN1yFQ",
        "outputId": "46a087e1-f4aa-45a1-88fd-daff31cf5e35"
      },
      "source": [
        "prefix=''\n",
        "\n",
        "def nq_dataset_task(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_task(\"train\").take(5)):\n",
        "    print(ex)\n",
        "\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join([prefix + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label}\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "      \n",
        "t5.data.TaskRegistry.remove('finetuning')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"finetuning\",\n",
        "    dataset_fn=nq_dataset_task,\n",
        "    splits=[\"train\",\"validation\"],\n",
        "    text_preprocessor=preprocessing,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'protected String userTenancyPathForCached(final ApplicationUser applicationUser) <extra_id_0>', 'output': b'{ return queryResultsCache.execute(new Callable<String>() { @Override public String call() throws Exception { return userTenancyPathFor(applicationUser); } }, TenantedAuthorizationFacetDefault.class, \"userTenancyPathFor\", applicationUser); }'}\n",
            "{'input': b'protected String userTenancyPathForCached(final ApplicationUser applicationUser) { return queryResultsCache.execute(new Callable<String>() <extra_id_0>, TenantedAuthorizationFacetDefault.class, \"userTenancyPathFor\", applicationUser); }', 'output': b'{ @Override public String call() throws Exception { return userTenancyPathFor(applicationUser); } }'}\n",
            "{'input': b'public void setLastCreatedDialogId(final long dialog_id, final boolean set) { Utilities.stageQueue.postRunnable(new Runnable() <extra_id_0>); }', 'output': b'{ @Override public void run() { if (set) { createdDialogIds.add(dialog_id); } else { createdDialogIds.remove(dialog_id); } } }'}\n",
            "{'input': b'public void setLastCreatedDialogId(final long dialog_id, final boolean set) { Utilities.stageQueue.postRunnable(new Runnable() { @Override public void run() <extra_id_0> }); }', 'output': b'{ if (set) { createdDialogIds.add(dialog_id); } else { createdDialogIds.remove(dialog_id); } }'}\n",
            "{'input': b'public static XNElement createRequest(String function, Object... nameValue) <extra_id_0>', 'output': b'{ XNElement result = new XNElement(function); for (int i = 0; i < nameValue.length; i += 2) { result.set((String)nameValue[i], nameValue[i + 1]); } return result; }'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f99793f34d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-GatnV2dLG",
        "outputId": "ac9c8d7f-209e-40bd-bcee-eed3578fb1c3"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"finetuning\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'public Document newDocument() { if (builder == null) <extra_id_0> return builder.newDocument(); }', 'inputs': array([   12,  1168,    24,   464,    16,     7,    21,    17,   534,\n",
            "          40,    30,     8, 32099,    14,   259,     4,    74,   464,\n",
            "          18,     6,     1], dtype=int32), 'targets_pretokenized': b'{ try { builder = DocumentBuilderFactory.newInstance().newDocumentBuilder(); } catch (ParserConfigurationException e) { e.printStackTrace(); } catch (FactoryConfigurationError e) { e.printStackTrace(); } }', 'targets': array([   7,   93,    7,  259,   11, 6723,  149,    4, 1248,   37,   74,\n",
            "       9257,   18,    6,   97,   17,  519,  186,   38,   57,    8,    7,\n",
            "         57,    4,  864,   18,    6,   97,   17,  149,  186,  287,   57,\n",
            "          8,    7,   57,    4,  864,   18,    6,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public static boolean fastCompareDocs(JsonNode sourceDocument, JsonNode destinationDocument, List<String> exclusionPaths, boolean ignoreTimestampMSDiffs) { try { JsonDiff diff = new JsonDiff(); diff.setOption(JsonDiff.Option.ARRAY_ORDER_INSIGNIFICANT); diff.setOption(JsonDiff.Option.RETURN_LEAVES_ONLY); diff.setFilter(new AbstractFieldFilter() { public boolean includeField(List<String> fieldName) { return !fieldName.get(fieldName.size() - 1).endsWith(\"#\"); } }); List<JsonDelta> list = diff.computeDiff(sourceDocument, destinationDocument); for (JsonDelta x : list) { String field = x.getField(); if (!isExcluded(exclusionPaths, field)) <extra_id_0> } } catch (Exception e) { LOGGER.error(\"Cannot compare docs:{}\", e, e); } return false; }', 'inputs': array([   12,    48,    45,  8216,  4330,  6251,     5,  9032,   345,\n",
            "         464,     9,  6121,  1759,   464,     9,    85,    25,    31,\n",
            "          29,     3, 20385,  1735,     9,    45,  1599,  1308,  2656,\n",
            "        1809,    22,     8,     7,    93,     7,  2121,  1809,  2946,\n",
            "          11,    24,  2121,  1809,    18,  2946,     4,    63,   721,\n",
            "           5,   974,  1809,     4,   721,     4,  3449,     2,    15,\n",
            "        4411,    15,  1232, 11443,  3933,  3214,  8071,    10,  2946,\n",
            "           4,    63,   721,     5,   974,  1809,     4,   721,     4,\n",
            "        8960,    15, 29418,    15,  4295,     2,    10,  2946,     4,\n",
            "       12406,     5,    74,   942,   219,   251,    16,     7,    12,\n",
            "          45,  1770,   219,     5,    71,    25,    31,    29,  2094,\n",
            "           8,     7,    14,   232,  2658,     4,    33,     5,  2658,\n",
            "           4,   134,    16,   139,   637,     4,  1701,    28,     2,\n",
            "          46,     6,     6,    10,    85,    25,   974,  1814,    29,\n",
            "         247,    11,  2946,     4,  3553,  1809,     5,   592,   464,\n",
            "           9,  1759,   464,    10,    50,    17,   974,  1814,   205,\n",
            "          58,   247,     8,     7,    26,   434,    11,   205,     4,\n",
            "        3475,    18,    21,   124,   112,  6617,     5, 20385,  1735,\n",
            "           9,   434,     8,     8, 32099,     6,     6,    97,    17,\n",
            "          38,    57,     8,     7,   990,     4,   282,    28,  1657,\n",
            "        1402, 15334, 16144,    57,     9,    57,    10,     6,    14,\n",
            "          76,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ if (reallyDifferent(x.getNode1(), x.getNode2(), ignoreTimestampMSDiffs)) { return true; } }', 'targets': array([   7,   21,   17, 5341,  859, 9568,    5,  138,    4, 3269,   94,\n",
            "         72,  205,    4, 3269,   80,   72, 1599, 1308, 2656, 1809,   22,\n",
            "          8,    8,    7,   14,   89,   13,    6,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public <ResultT> Task<ResultT> execute( @Nonnull final AwsRequest request, @Nonnull final Class<ResultT> resultClass) <extra_id_0>', 'inputs': array([   12,   136,   195,    70,    29,  2881,    25,   195,    70,\n",
            "          29,   768,     5,    19,   790,    44,     3, 14211,   125,\n",
            "         190,     9,    19,   790,    44,   335,    25,   195,    70,\n",
            "          29,    84,   114,     8, 32099,     1], dtype=int32), 'targets_pretokenized': b'{ return dispatcher.dispatchTask(new Callable<ResultT>() { @Override public ResultT call() { return proxy.execute(request, resultClass); } }); }', 'targets': array([    7,    14,  7977,     4,  5514,   389,     5,    74, 12458,\n",
            "          25,   195,    70,    29,    16,     7,    19,    27,    12,\n",
            "        3026,    70,   472,    16,     7,    14,  1661,     4,   784,\n",
            "           5,   365,     9,    84,   114,    10,     6,     6,    10,\n",
            "           6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'@Override public Set<URI> listOutputs(URI operationUri) <extra_id_0>', 'inputs': array([   19,    27,    12,   300,    25,   445,    29,   247,  7391,\n",
            "           5,   445,  1590,   362,     8, 32099,     1], dtype=int32), 'targets_pretokenized': b'{ if (operationUri == null) { return ImmutableSet.of(); } return ImmutableSet.copyOf(this.opOutputMap.get(operationUri)); }', 'targets': array([   7,   21,   17, 3997,  362,   40,   30,    8,    7,   14, 6419,\n",
            "          4,  579,   18,    6,   14, 6419,    4, 3205,    5,   75,    4,\n",
            "       1162,  525,  100,    4,   33,    5, 3997,  362,   79,    6,    1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'private Path getDestDir() { if (destDir == null) { if (!configuration.destDirName.isEmpty() || !fileManager.hasLocation(DocumentationTool.Location.DOCUMENTATION_OUTPUT)) <extra_id_0> destDir = fileManager.getLocationAsPaths(DocumentationTool.Location.DOCUMENTATION_OUTPUT).iterator().next(); } return destDir; }', 'inputs': array([   47,  1191,     3, 19715,   490,    16,     7,    21,    17,\n",
            "       27378,    40,    30,     8,     7,    21,   124,  1382,     4,\n",
            "       27378,    66,     4,   280,    16,     3,     2,   232,   296,\n",
            "         121,     4,   521,   331,     5,  7706,  1483,     4,   331,\n",
            "           4,  7144,  2832,    15,  3822,     8,     8, 32099, 19440,\n",
            "          11,   191,   121,     4,  2331,   787,  1735,     5,  7706,\n",
            "        1483,     4,   331,     4,  7144,  2832,    15,  3822,     8,\n",
            "           4,   774,    37,   395,    18,     6,    14, 19440,    13,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'{ try { String dirName = configuration.destDirName.isEmpty() ? \".\" : configuration.destDirName; Path dir = Paths.get(dirName); fileManager.setLocationFromPaths(DocumentationTool.Location.DOCUMENTATION_OUTPUT, Arrays.asList(dir)); } catch (IOException e) { throw new DocletAbortException(e); } }', 'targets': array([    7,    93,     7,    26, 21382,    11,   739,     4, 27378,\n",
            "          66,     4,   280,    16,     3,     2,  2421,    58,   739,\n",
            "           4, 27378,    66,    13,  1191,  1337,    11, 10097,     4,\n",
            "          33,     5,  1255,    66,    10,   191,   121,     4,  7323,\n",
            "       20718,    22,     5,  7706,  1483,     4,   331,     4,  7144,\n",
            "        2832,    15,  3822,     9,   967,     4,   920,     5,  1255,\n",
            "          79,     6,    97,    17,   487,    57,     8,     7,    78,\n",
            "          24,     3, 28290,  6744,    38,     5,   110,    10,     6,\n",
            "           6,     1], dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkLJ-FpDF8CD"
      },
      "source": [
        "### Hyper Parameter tuning\n",
        "You can run the HP tuning using the following cells.  \n",
        "Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in), *PATH_GIN_FILE* (the gin file configuration for this HP tuning) and *PRETRAINED_DIR* (the folder that contains the pretrained model).  \n",
        "**Keep attention** to change the *pretrained_model_dir* in finetune step (if you are starting the HP tuning from scratch you have to set the value *PRETRAINED_DIR*, if you are restarting the HP tuning from a previous saved checkpoint you have to set the value *MODEL_DIR*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz1a1TxFNKmx",
        "outputId": "84ce2206-ae4b-45f3-9fa9-c70d717efb45"
      },
      "source": [
        "## this is useful if you have more than one task\n",
        "# def _rate_num_input_examples(task):\n",
        "#   if \"train\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"train\"))\n",
        "#   elif \"validation\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"validation\"))\n",
        "#   else:\n",
        "#     raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "# t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "# t5.data.MixtureRegistry.add(\n",
        "#     \"all_tasks\",\n",
        "#     [\"java_construct\", \"java_token\", \"java_block\", \"android_construct\", \"android_token\", \"android_block\"],\n",
        "#     default_rate=_rate_num_input_examples\n",
        "#      #default_rate=1.0\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<t5.seqio.dataset_providers.Mixture at 0x7f4a4465d470>"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular\n",
        "\n",
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/finetuning/0605/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 5000),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = slanted_triangular,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oHp5ScE7nf2",
        "outputId": "80fedcb6-32ec-403c-fec3-333d1fab1170"
      },
      "source": [
        "PATH_GIN_FILE = 'gs://bucket_block_completion/finetuning/0605/operative_config_slanted.gin'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 400000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"finetuning\",\n",
        "        pretrained_model_dir=MODEL_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0605/operative_config_slanted.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0605/operative_config_slanted.gin\n",
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0605/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0605/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0605/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.31.237.90:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.31.237.90:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.31.237.90:8470', '_evaluation_master': 'grpc://10.31.237.90:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f9b928281d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.31.237.90:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.31.237.90:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -2243418312430585975)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -7093114418152277797)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -9126512489086005918)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -7962919866980157275)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4442200468869878515)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -4066074438239971524)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7279533561263478277)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -1941512956015422990)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6779238840457830433)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3256165418554087900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2057799675911147472)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:401: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('d_ff', 'model'), ('experts', 'batch'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model'), ('batch', 'batch')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f98f35db810>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 6.85e+08\n",
            " allreduce/[0]: 6.85e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 2.01e+08\n",
            "einsum: 4.06e+13\n",
            "einsum_unique: 4.05e+13\n",
            "output: 3.66e+11\n",
            " output/AddOperation: 6.7e+10\n",
            " output/BinaryOpWithBroadcasting: 4.51e+09\n",
            " output/BroadcastOperation: 2.02e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 1.46e+11\n",
            " output/ImportOperation: 6.29e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 1.34e+10\n",
            " output/RandomOperation: 2.96e+07\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 7.93e+09\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.39e+08\n",
            " output/ScalarMultiplyOperation: 3.64e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 7.48e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 1.39e+10\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 3.58e+11\n",
            " output_unique/AddOperation: 6.67e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.47e+09\n",
            " output_unique/BroadcastOperation: 2.02e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 1.42e+11\n",
            " output_unique/ImportOperation: 7.87e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 1.27e+10\n",
            " output_unique/RandomOperation: 2.96e+07\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 7.76e+09\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 7.1e+07\n",
            " output_unique/ScalarMultiplyOperation: 3.55e+09\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 7.25e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 1.39e+10\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://bucket_block_completion/finetuning/0605/model/model.ckpt-597800:\n",
            "INFO:tensorflow:Variables in gs://bucket_block_completion/finetuning/0605/model/model.ckpt-597800 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://bucket_block_completion/finetuning/0605/model/model.ckpt-597800:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0605/model/model.ckpt-597800\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1165: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:758: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 597800...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 597800 into gs://bucket_block_completion/finetuning/0605/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 597800...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 96)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 597900\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 90)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 598000 (63.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57567\n",
            "INFO:tensorflow:examples/sec: 403.371\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 85)\n",
            "INFO:tensorflow:loss = 0.09667969, step = 598100 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.287\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 80)\n",
            "INFO:tensorflow:loss = 0.100097656, step = 598200 (63.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5691\n",
            "INFO:tensorflow:examples/sec: 401.689\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 75)\n",
            "INFO:tensorflow:loss = 0.099609375, step = 598300 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.295\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 70)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 598400 (63.696 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56994\n",
            "INFO:tensorflow:examples/sec: 401.905\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 65)\n",
            "INFO:tensorflow:loss = 0.10986328, step = 598500 (63.877 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56552\n",
            "INFO:tensorflow:examples/sec: 400.774\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 59)\n",
            "INFO:tensorflow:loss = 0.10986328, step = 598600 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.283\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 54)\n",
            "INFO:tensorflow:loss = 0.123535156, step = 598700 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 49)\n",
            "INFO:tensorflow:loss = 0.09472656, step = 598800 (63.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56949\n",
            "INFO:tensorflow:examples/sec: 401.79\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 44)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 598900 (63.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5832\n",
            "INFO:tensorflow:examples/sec: 405.3\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 39)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 599000 (63.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57017\n",
            "INFO:tensorflow:examples/sec: 401.964\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (12, 34)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 599100 (63.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57108\n",
            "INFO:tensorflow:examples/sec: 402.196\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 29)\n",
            "INFO:tensorflow:loss = 0.09863281, step = 599200 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.292\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 24)\n",
            "INFO:tensorflow:loss = 0.10058594, step = 599300 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58319\n",
            "INFO:tensorflow:examples/sec: 405.297\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 19)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 599400 (63.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57047\n",
            "INFO:tensorflow:examples/sec: 402.04\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (16, 14)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 599500 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.284\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 9)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 599600 (63.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56965\n",
            "INFO:tensorflow:examples/sec: 401.831\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 4)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 599700 (63.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56968\n",
            "INFO:tensorflow:examples/sec: 401.838\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 96)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 599800 (63.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58322\n",
            "INFO:tensorflow:examples/sec: 405.306\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 91)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 599900 (63.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5832\n",
            "INFO:tensorflow:examples/sec: 405.298\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (21, 86)\n",
            "INFO:tensorflow:loss = 0.11376953, step = 600000 (63.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57011\n",
            "INFO:tensorflow:examples/sec: 401.947\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 81)\n",
            "INFO:tensorflow:loss = 0.12109375, step = 600100 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.286\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (23, 76)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 600200 (63.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57076\n",
            "INFO:tensorflow:examples/sec: 402.114\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 71)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 600300 (63.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57031\n",
            "INFO:tensorflow:examples/sec: 402\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 66)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 600400 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (26, 61)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 600500 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 56)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 600600 (63.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57056\n",
            "INFO:tensorflow:examples/sec: 402.064\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (28, 51)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 600700 (63.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58322\n",
            "INFO:tensorflow:examples/sec: 405.304\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 46)\n",
            "INFO:tensorflow:loss = 0.12597656, step = 600800 (63.697 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56994\n",
            "INFO:tensorflow:examples/sec: 401.904\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 41)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 600900 (63.749 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56866\n",
            "INFO:tensorflow:examples/sec: 401.576\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 36)\n",
            "INFO:tensorflow:loss = 0.09716797, step = 601000 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.283\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (32, 31)\n",
            "INFO:tensorflow:loss = 0.122558594, step = 601100 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.285\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (33, 26)\n",
            "INFO:tensorflow:loss = 0.12011719, step = 601200 (63.701 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56984\n",
            "INFO:tensorflow:examples/sec: 401.879\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 21)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 601300 (63.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5832\n",
            "INFO:tensorflow:examples/sec: 405.299\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (35, 16)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 601400 (63.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57115\n",
            "INFO:tensorflow:examples/sec: 402.215\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 11)\n",
            "INFO:tensorflow:loss = 0.10498047, step = 601500 (63.656 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57096\n",
            "INFO:tensorflow:examples/sec: 402.167\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (37, 6)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 601600 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.295\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 1)\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 97)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 601700 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.287\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 92)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 601800 (63.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56936\n",
            "INFO:tensorflow:examples/sec: 401.756\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 87)\n",
            "INFO:tensorflow:loss = 0.106933594, step = 601900 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58316\n",
            "INFO:tensorflow:examples/sec: 405.29\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (41, 82)\n",
            "INFO:tensorflow:loss = 0.123046875, step = 602000 (63.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57065\n",
            "INFO:tensorflow:examples/sec: 402.087\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (42, 77)\n",
            "INFO:tensorflow:loss = 0.11816406, step = 602100 (63.683 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57029\n",
            "INFO:tensorflow:examples/sec: 401.993\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (43, 72)\n",
            "INFO:tensorflow:loss = 0.123046875, step = 602200 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58309\n",
            "INFO:tensorflow:examples/sec: 405.272\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (44, 67)\n",
            "INFO:tensorflow:loss = 0.10986328, step = 602300 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58319\n",
            "INFO:tensorflow:examples/sec: 405.298\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (45, 62)\n",
            "INFO:tensorflow:loss = 0.109375, step = 602400 (63.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57008\n",
            "INFO:tensorflow:examples/sec: 401.94\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (46, 57)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 602500 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.295\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (47, 52)\n",
            "INFO:tensorflow:loss = 0.09863281, step = 602600 (63.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57059\n",
            "INFO:tensorflow:examples/sec: 402.072\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (48, 47)\n",
            "INFO:tensorflow:loss = 0.12988281, step = 602700 (63.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57049\n",
            "INFO:tensorflow:examples/sec: 402.044\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 42)\n",
            "INFO:tensorflow:loss = 0.12011719, step = 602800 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (50, 37)\n",
            "INFO:tensorflow:loss = 0.09326172, step = 602900 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58316\n",
            "INFO:tensorflow:examples/sec: 405.288\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 602900...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 602900 into gs://bucket_block_completion/finetuning/0605/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 602900...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (51, 23)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 603000 (69.059 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44804\n",
            "INFO:tensorflow:examples/sec: 370.698\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (52, 18)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 603100 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.292\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (53, 11)\n",
            "INFO:tensorflow:loss = 0.1171875, step = 603200 (64.762 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.54412\n",
            "INFO:tensorflow:examples/sec: 395.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (54, 6)\n",
            "INFO:tensorflow:loss = 0.12451172, step = 603300 (63.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57142\n",
            "INFO:tensorflow:examples/sec: 402.283\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (55, 1)\n",
            "INFO:tensorflow:Outfeed finished for iteration (55, 97)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 603400 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.291\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (56, 92)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 603500 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.295\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (57, 87)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 603600 (63.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57091\n",
            "INFO:tensorflow:examples/sec: 402.154\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (58, 82)\n",
            "INFO:tensorflow:loss = 0.103515625, step = 603700 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.293\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (59, 77)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 603800 (63.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57064\n",
            "INFO:tensorflow:examples/sec: 402.084\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (60, 72)\n",
            "INFO:tensorflow:loss = 0.10253906, step = 603900 (63.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56851\n",
            "INFO:tensorflow:examples/sec: 401.539\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (61, 67)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 604000 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (62, 62)\n",
            "INFO:tensorflow:loss = 0.12695312, step = 604100 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.291\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (63, 57)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 604200 (63.656 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57095\n",
            "INFO:tensorflow:examples/sec: 402.164\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (64, 52)\n",
            "INFO:tensorflow:loss = 0.09667969, step = 604300 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58319\n",
            "INFO:tensorflow:examples/sec: 405.296\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (65, 47)\n",
            "INFO:tensorflow:loss = 0.095703125, step = 604400 (63.701 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56985\n",
            "INFO:tensorflow:examples/sec: 401.881\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (66, 42)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 604500 (63.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5698\n",
            "INFO:tensorflow:examples/sec: 401.868\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (67, 37)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 604600 (63.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5832\n",
            "INFO:tensorflow:examples/sec: 405.3\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (68, 32)\n",
            "INFO:tensorflow:loss = 0.125, step = 604700 (63.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5832\n",
            "INFO:tensorflow:examples/sec: 405.299\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (69, 27)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 604800 (63.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57046\n",
            "INFO:tensorflow:examples/sec: 402.037\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (70, 22)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 604900 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.29\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (71, 17)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 605000 (63.677 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57043\n",
            "INFO:tensorflow:examples/sec: 402.029\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (72, 12)\n",
            "INFO:tensorflow:loss = 0.12109375, step = 605100 (63.685 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57023\n",
            "INFO:tensorflow:examples/sec: 401.98\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (73, 7)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 605200 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58319\n",
            "INFO:tensorflow:examples/sec: 405.296\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (74, 2)\n",
            "INFO:tensorflow:Outfeed finished for iteration (74, 98)\n",
            "INFO:tensorflow:loss = 0.107421875, step = 605300 (63.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5832\n",
            "INFO:tensorflow:examples/sec: 405.3\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (75, 93)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 605400 (63.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56779\n",
            "INFO:tensorflow:examples/sec: 401.355\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (76, 88)\n",
            "INFO:tensorflow:loss = 0.10986328, step = 605500 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.293\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (77, 83)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 605600 (63.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56822\n",
            "INFO:tensorflow:examples/sec: 401.464\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (78, 78)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 605700 (63.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57111\n",
            "INFO:tensorflow:examples/sec: 402.205\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (79, 73)\n",
            "INFO:tensorflow:loss = 0.11035156, step = 605800 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.293\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (80, 68)\n",
            "INFO:tensorflow:loss = 0.10986328, step = 605900 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58319\n",
            "INFO:tensorflow:examples/sec: 405.296\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (81, 63)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 606000 (63.678 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57041\n",
            "INFO:tensorflow:examples/sec: 402.026\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (82, 58)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 606100 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.292\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (83, 53)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 606200 (63.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57092\n",
            "INFO:tensorflow:examples/sec: 402.155\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (84, 48)\n",
            "INFO:tensorflow:loss = 0.11816406, step = 606300 (63.692 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57006\n",
            "INFO:tensorflow:examples/sec: 401.935\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (85, 43)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 606400 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.293\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (86, 38)\n",
            "INFO:tensorflow:loss = 0.10449219, step = 606500 (63.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5832\n",
            "INFO:tensorflow:examples/sec: 405.298\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (87, 33)\n",
            "INFO:tensorflow:loss = 0.12402344, step = 606600 (63.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56827\n",
            "INFO:tensorflow:examples/sec: 401.478\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (88, 28)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 606700 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (89, 23)\n",
            "INFO:tensorflow:loss = 0.103515625, step = 606800 (63.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57088\n",
            "INFO:tensorflow:examples/sec: 402.145\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (90, 18)\n",
            "INFO:tensorflow:loss = 0.12109375, step = 606900 (63.709 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56965\n",
            "INFO:tensorflow:examples/sec: 401.83\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (91, 13)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 607000 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.291\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (92, 8)\n",
            "INFO:tensorflow:loss = 0.10595703, step = 607100 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.29\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (93, 3)\n",
            "INFO:tensorflow:Outfeed finished for iteration (93, 99)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 607200 (63.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57101\n",
            "INFO:tensorflow:examples/sec: 402.178\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (94, 94)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 607300 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58316\n",
            "INFO:tensorflow:examples/sec: 405.29\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (95, 88)\n",
            "INFO:tensorflow:loss = 0.10595703, step = 607400 (63.882 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5654\n",
            "INFO:tensorflow:examples/sec: 400.741\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (96, 83)\n",
            "INFO:tensorflow:loss = 0.12402344, step = 607500 (63.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57018\n",
            "INFO:tensorflow:examples/sec: 401.967\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (97, 78)\n",
            "INFO:tensorflow:loss = 0.123046875, step = 607600 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.28\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (98, 73)\n",
            "INFO:tensorflow:loss = 0.119140625, step = 607700 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.293\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (99, 68)\n",
            "INFO:tensorflow:loss = 0.09863281, step = 607800 (63.694 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57001\n",
            "INFO:tensorflow:examples/sec: 401.922\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (100, 63)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 607900 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.286\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (101, 58)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 608000 (63.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5703\n",
            "INFO:tensorflow:examples/sec: 401.997\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 608000...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 608000 into gs://bucket_block_completion/finetuning/0605/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 608000...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (102, 44)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 608100 (69.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43502\n",
            "INFO:tensorflow:examples/sec: 367.364\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (103, 38)\n",
            "INFO:tensorflow:loss = 0.10498047, step = 608200 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.294\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (104, 33)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 608300 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58317\n",
            "INFO:tensorflow:examples/sec: 405.292\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (105, 28)\n",
            "INFO:tensorflow:loss = 0.10595703, step = 608400 (63.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57144\n",
            "INFO:tensorflow:examples/sec: 402.29\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (106, 23)\n",
            "INFO:tensorflow:loss = 0.119140625, step = 608500 (63.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58318\n",
            "INFO:tensorflow:examples/sec: 405.293\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (107, 18)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 608600 (63.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57109\n",
            "INFO:tensorflow:examples/sec: 402.199\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (108, 13)\n",
            "INFO:tensorflow:loss = 0.115234375, step = 608700 (64.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.54511\n",
            "INFO:tensorflow:examples/sec: 395.549\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (109, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CviTb69IJUQ_"
      },
      "source": [
        "### Evaluate the performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJYVynoR5hDe"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 512\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"finetuning\",\n",
        "    # mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1 #evaluate only last checkpoint\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}