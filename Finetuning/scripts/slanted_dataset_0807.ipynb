{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "slanted_dataset_0807.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugT1qQ0XEW8U"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1MRzBLtex2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4471de35-571b-4d87-9b44-77e4590ad778"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "!pip install -qU t5\n",
        "\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_block_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "!pip install tensorflow-gcs-config #2.7.0 is broken\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "     |████████████████████████████████| 153 kB 5.4 MB/s            \n",
            "     |████████████████████████████████| 3.1 MB 33.0 MB/s            \n",
            "     |████████████████████████████████| 4.9 MB 60.6 MB/s            \n",
            "     |████████████████████████████████| 4.0 MB 65.3 MB/s            \n",
            "     |████████████████████████████████| 366 kB 79.7 MB/s            \n",
            "     |████████████████████████████████| 1.2 MB 62.1 MB/s            \n",
            "     |████████████████████████████████| 90 kB 10.5 MB/s            \n",
            "     |████████████████████████████████| 286 kB 72.9 MB/s            \n",
            "     |████████████████████████████████| 59 kB 5.8 MB/s             \n",
            "     |████████████████████████████████| 895 kB 73.7 MB/s            \n",
            "     |████████████████████████████████| 596 kB 72.4 MB/s            \n",
            "     |████████████████████████████████| 3.3 MB 60.3 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-gcs-config in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.39.255.178:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poax9QWkEeMV"
      },
      "source": [
        "### Loading of the tsv files\n",
        "We loaded the tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "\n",
        "nq_tsv_path = {\n",
        "    \"train\":      'gs://bucket_block_completion/dataset_08_07/train.tsv',\n",
        "    \"validation\": 'gs://bucket_block_completion/dataset_08_07/test.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples = dict(train=1197310, validation=15742)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Y8Tje7FiNi"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WK7uMr3zYuQ"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_block_completion/code.model'\n",
        "vocab_path = 'gs://bucket_block_completion/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP4yvsTe4oAH"
      },
      "source": [
        "## If you have more than one task you have to use the prefix, otherwise it is not mandatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGp5FiN1yFQ",
        "outputId": "66cd3ab7-6c77-4cc2-8956-2d0070d083ae"
      },
      "source": [
        "prefix=''\n",
        "\n",
        "def nq_dataset_task(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_task(\"train\").take(5)):\n",
        "    print(ex)\n",
        "\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join([prefix + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label}\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "      \n",
        "t5.data.TaskRegistry.remove('finetuning')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"finetuning\",\n",
        "    dataset_fn=nq_dataset_task,\n",
        "    splits=[\"train\",\"validation\"],\n",
        "    text_preprocessor=preprocessing,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'public static void saveBitmapToDevice(Bitmap btmp, String filePath, String imageName) { File file = new File (filePath, imageName); if (file.exists ()) file.delete (); try <extra_id_0> catch (Exception e) { e.printStackTrace(); } }', 'output': b'{ FileOutputStream out = new FileOutputStream(file); btmp.compress(Bitmap.CompressFormat.JPEG, 90, out); out.flush(); out.close(); }'}\n",
            "{'input': b'@Override public Dampening updateGroupDampening(String tenantId, Dampening groupDampening) throws Exception { if (isEmpty(tenantId)) { throw new IllegalArgumentException(\"TenantId must be not null\"); } if (isEmpty(groupDampening)) { throw new IllegalArgumentException(\"DampeningId and TriggerId must be not null\"); } try { deferNotifications(); checkTenantId(tenantId, groupDampening); String groupId = groupDampening.getTriggerId(); Trigger groupTrigger = getTrigger(tenantId, groupId); if (!groupTrigger.isGroup()) { throw new IllegalArgumentException( \"Trigger [\" + tenantId + \"/\" + groupId + \"] is not a group trigger.\"); } Collection<Trigger> memberTriggers = getMemberTriggers(tenantId, groupId, false); for (Trigger member : memberTriggers) <extra_id_0> groupDampening.setTriggerId(groupTrigger.getId()); return updateDampening(groupDampening); } finally { releaseNotifications(); } }', 'output': b'{ groupDampening.setTriggerId(member.getId()); updateDampening(groupDampening); }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) <extra_id_0> return rv.toString(); } return toXMLString(); }', 'output': b'{ XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) { XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); } }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) { XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) <extra_id_0> } return rv.toString(); } return toXMLString(); }', 'output': b'{ XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); }'}\n",
            "{'input': b'private void getClassAnnotationsFromDTO(Object config, DTODescription description) <extra_id_0>', 'output': b'{ Annotation[] declaredAnnotations = getTemplateClass(config).getDeclaredAnnotations(); if (declaredAnnotations != null) { for (Annotation annotation : declaredAnnotations) { description.addAnnotation(annotation); } } }'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7fe30b868a90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-GatnV2dLG",
        "outputId": "1617c2f6-61e4-4aed-ff15-3d1699362d1f"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"finetuning\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'private <P extends ThreadPoolDefinition & ResourceDefinition> void parseThreadPool(P pool, XMLExtendedStreamReader reader, PathAddress parentAddress, Map<PathAddress, ModelNode> operations) throws XMLStreamException { PathAddress address = parentAddress.append(pool.getPathElement()); ModelNode operation = Util.createAddOperation(address); operations.put(address, operation); for (int i = 0; i < reader.getAttributeCount(); i++) { XMLAttribute attribute = XMLAttribute.forName(reader.getAttributeLocalName(i)); switch (attribute) { case MIN_THREADS: <extra_id_0> case MAX_THREADS: { readAttribute(reader, i, operation, pool.getMaxThreads()); break; } case QUEUE_LENGTH: { if (pool.getQueueLength() != null) { readAttribute(reader, i, operation, pool.getQueueLength()); } break; } case KEEPALIVE_TIME: { readAttribute(reader, i, operation, pool.getKeepAliveTime()); break; } default: { throw ParseUtils.unexpectedAttribute(reader, i); } } } ParseUtils.requireNoContent(reader); }', 'inputs': array([   47,   136,   364,   324,     3,  4627,   530,   524,  1429,\n",
            "         530,    29,    20,   545,  4627,     5,   364,  1948,     9,\n",
            "           3,     2,   575,  3015, 21250,   931,     9,  1191,   455,\n",
            "         340,   455,     9,   188,    25,   128,   455,     9,  2531,\n",
            "         152,    29,  6163,     8,    42,     3,     2,  5110,    38,\n",
            "           7,  1191,   455,   906,    11,   340,   455,     4,   109,\n",
            "           5,  3170,     4,  1224,   177,    39,  2531,   152,  1590,\n",
            "          11,  3396,     4,   160,  1067,   745,     5,  1195,    10,\n",
            "        6163,     4,   120,     5,  1195,     9,  1590,    10,    50,\n",
            "          17,    53,    65,    11,   116,    65,   136,   931,     4,\n",
            "        1451,   182,    18,    65,   227,     7,     3,     2,   575,\n",
            "         441,  1265,    11,     3,     2,   575,   441,     4,  2861,\n",
            "           5,  1832,     4,  1451, 20170,     5,    86,    79,   695,\n",
            "          17,  2095,     8,     7,   234, 10011,    15, 19823,    56,\n",
            "       32099,   234,  3249,     2,    15, 19823,    56,     7,   384,\n",
            "         441,     5,  1832,     9,    65,     9,  1590,     9,  1948,\n",
            "           4,  2359,  3165,    39,   591,    13,     6,   234,     3,\n",
            "           2,  7589,    15,  1677,    56,     7,    21,    17,  3170,\n",
            "           4,    33,     2,   514,   528,    16,    49,    30,     8,\n",
            "           7,   384,   441,     5,  1832,     9,    65,     9,  1590,\n",
            "           9,  1948,     4,    33,     2,   514,   528,    39,     6,\n",
            "         591,    13,     6,   234,     3, 11138, 24285,    15,  1739,\n",
            "          56,     7,   384,   441,     5,  1832,     9,    65,     9,\n",
            "        1590,     9,  1948,     4,    33, 10983,   199,    39,   591,\n",
            "          13,     6,   289,    56,     7,    78,  4982,   217,     4,\n",
            "       13763,   441,     5,  1832,     9,    65,    10,     6,     6,\n",
            "           6,  4982,   217,     4,  7602,   496,   399,     5,  1832,\n",
            "          10,     6,     1], dtype=int32), 'targets_pretokenized': b'{ if (pool.getMinThreads() != null) { readAttribute(reader, i, operation, pool.getMinThreads()); } break; }', 'targets': array([   7,   21,   17, 3170,    4, 4344, 3165,   16,   49,   30,    8,\n",
            "          7,  384,  441,    5, 1832,    9,   65,    9, 1590,    9, 1948,\n",
            "          4, 4344, 3165,   39,    6,  591,   13,    6,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_texto); action = getIntent().getStringExtra(\"action\"); texto = findViewById(R.id.tvTexto); switch (action) { case \"privacy\": texto.setText(fromHtml(getString(R.string.privacy_text))); setTitle(getString(R.string.action_privacy)); break; case \"third\": Markwon.setMarkdown(texto, getString(R.string.third_text)); setTitle(getString(R.string.action_third)); break; case \"license\": try { texto.setText(fromHtml(getString(R.string.license_text))); setTitle(getString(R.string.action_license)); getSupportActionBar().setDisplayHomeAsUpEnabled(false); } catch (Exception e) <extra_id_0> break; } }', 'inputs': array([   73,    20,  1675,     5,   674,  1914,   119,     8,     7,\n",
            "          52,     4,  1869,     5,  2499,   119,    10,  6138,     5,\n",
            "         144,     4,  1179,     4,  1338,    15,   443,   226,    10,\n",
            "         647,    11,  8405,    37, 10276,    28,   915,    46,   385,\n",
            "         226,    11,  3510,     5,   144,     4,   111,     4,  9036,\n",
            "         204,   226,    10,   695,    17,   915,     8,     7,   234,\n",
            "          32, 17006,  2081,   385,   226,     4,   811,     5, 24452,\n",
            "           5,   416,     5,   144,     4,   383,     4, 17006,    15,\n",
            "         443,  1043,  6348,     5,   416,     5,   144,     4,   383,\n",
            "           4,   915,    15, 17006,    79,   591,    13,   234,    32,\n",
            "       20374,  2081,     3,  3341,   550,   298,     4,    63, 16105,\n",
            "           5,   443,   226,     9,  2467,     5,   144,     4,   383,\n",
            "           4, 20374,    15,   443,    79,  6348,     5,   416,     5,\n",
            "         144,     4,   383,     4,   915,    15, 20374,    79,   591,\n",
            "          13,   234,    32, 13745,  2081,    93,     7,   385,   226,\n",
            "           4,   811,     5, 24452,     5,   416,     5,   144,     4,\n",
            "         383,     4, 13745,    15,   443,  1043,  6348,     5,   416,\n",
            "           5,   144,     4,   383,     4,   915,    15, 13745,    79,\n",
            "          41, 11422,    37,  8090, 18353,   456,     5,   348,    10,\n",
            "           6,    97,    17,    38,    57,     8, 32099,   591,    13,\n",
            "           6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ Log.e(\"OPEN LICENSE\", \"exception\", e); startActivity(new Intent(TextoActivity.this, AboutActivity.class)); Intent browserIntent = new Intent(Intent.ACTION_VIEW, Uri.parse(\"https://www.gnu.org/licenses/gpl-3.0-standalone.html\")); startActivity(browserIntent); }', 'targets': array([    7,   319,     4,   110,    28,  4350,     3, 21962,    43,\n",
            "          32,  1315,    43,    57,    10,  4078,     5,    74,   604,\n",
            "           5,   204,   226,   435,     4,    75,     9,     3,  7116,\n",
            "         435,     4,    88,    79,   604,  4106,   527,    11,    24,\n",
            "         604,     5,   527,     4,  1023,    15,  2846,     9,  1561,\n",
            "           4,   655,    28,  3557,   998,  3723,     4,   423,  8475,\n",
            "           4,   372,    59, 13745,    22,    59,   423,  6028,    90,\n",
            "           2,     4,  5046, 18745,     4,  1955,   295,  4078,     5,\n",
            "        7090,   527,    10,     6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public static boolean hasHtmlMarkup(String text) <extra_id_0>', 'inputs': array([   12,    48,    45,   358,  2137,  6258,     5,    31,   385,\n",
            "           8, 32099,     1], dtype=int32), 'targets_pretokenized': b'{ if (StringUtils.isEmpty(text)) return false; return text.contains(\"<\") && text.contains(\">\"); }', 'targets': array([    7,    21,    17,  1417,     4,   280,     5,   443,     8,\n",
            "           8,    14,    76,    13,    14,   385,     4,   353,    28,\n",
            "          25,   118,    91,   385,     4,   353,     5, 14014,     6,\n",
            "           1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public static JSONObject serializeSipProfile(Context context, SipProfile profile) { JSONObject jsonProfile = serializeBaseSipProfile(profile); JSONArray jsonFilters = new JSONArray(); Cursor c = Filter.getFiltersCursorForAccount(context, profile.id); int numRows = c.getCount(); c.moveToFirst(); for (int i = 0; i < numRows; ++i) <extra_id_0> c.close(); try { jsonProfile.put(FILTER_KEY, jsonFilters); } catch (JSONException e) { Log.e(THIS_FILE, \"Impossible to add fitlers\", e); } return jsonProfile; }', 'inputs': array([   12,    48,  1327,  2528, 21802,     5,    92,   130,     9,\n",
            "           3, 21802,  1708,     8,     7,  1327,   884,   853,    11,\n",
            "        2528,   431, 21802,     5,  2223,    10,  4181,   884,  2405,\n",
            "          11,    24,  4181,    18,  2406,   202,    11,     3,   251,\n",
            "           4,    33,  2405,  1123,   203,   815,     5,   201,     9,\n",
            "        1708,     4,   111,    10,    35,     3, 13391,    11,   202,\n",
            "           4,  2984,    18,   202,     4,  7482,    18,    50,    17,\n",
            "          53,    65,    11,   116,    65,   136,     3, 13391,    13,\n",
            "        1282,    86,     8, 32099,   202,     4,   363,    18,    93,\n",
            "           7,   884,   853,     4,   120,     5,  4047,    15,   370,\n",
            "           2,     9,   884,  2405,    10,     6,    97,    17,  5075,\n",
            "          57,     8,     7,   319,     4,   110,     5, 15152,    15,\n",
            "        1371,     9,    32, 30391,    81,   162, 12039, 14143,    22,\n",
            "          43,    57,    10,     6,    14,   884,   853,    13,     6,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'{ Filter f = new Filter(c); try { jsonFilters.put(i, serializeBaseFilter(f)); } catch (JSONException e) { Log.e(THIS_FILE, \"Impossible to add fitler\", e); } c.moveToNext(); }', 'targets': array([    7,     3,   251,   328,    11,    24,     3,   251,     5,\n",
            "         167,    10,    93,     7,   884,  2405,     4,   120,     5,\n",
            "          86,     9,  2528,   431,   251,     5,   165,    79,     6,\n",
            "          97,    17,  5075,    57,     8,     7,   319,     4,   110,\n",
            "           5, 15152,    15,  1371,     9,    32, 30391,    81,   162,\n",
            "       12039, 14143,    43,    57,    10,     6,   202,     4,  9074,\n",
            "          18,     6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'protected void onCheckFeatured(CheckedTextView checkable) { checkable.setChecked(!checkable.isChecked()); if (callbacks != null) <extra_id_0> }', 'inputs': array([   73,    20,   170,   846,   934,   101,     5,  3537,  1515,\n",
            "         272,   367,     8,     7,   272,   367,     4,  4871,   933,\n",
            "         847,   367,     4,  5227,    39,    21,    17, 17341,    49,\n",
            "          30,     8, 32099,     6,     1], dtype=int32), 'targets_pretokenized': b'{ boolean checked = checkable.isChecked(); if (checkable == freeOnlyToggle) { callbacks.onFreeOnlyToggle(checked); } else if (checkable == featuredOnlyToggle) { callbacks.onFeaturedOnlyToggled(checked); } }', 'targets': array([    7,    45,  4751,    11,   272,   367,     4,  5227,    18,\n",
            "          21,    17,   847,   367,    40,  4914,  1222,  4044,     8,\n",
            "           7,  7320,     4,   298,  3206,  1222,  4044,     5,  7302,\n",
            "          10,     6,    77,    21,    17,   847,   367,    40,  2166,\n",
            "         101,  1222,  4044,     8,     7,  7320,     4,   298,   934,\n",
            "         101,  1222, 20970,     5,  7302,    10,     6,     6,     1],\n",
            "      dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkLJ-FpDF8CD"
      },
      "source": [
        "### Hyper Parameter tuning\n",
        "You can run the HP tuning using the following cells.  \n",
        "Please set the correct path of the variable *MODEL_DIR* (the path to save the pretrained model in), *PATH_GIN_FILE* (the gin file configuration for this HP tuning) and *PRETRAINED_DIR* (the folder that contains the pretrained model).  \n",
        "**Keep attention** to change the *pretrained_model_dir* in finetune step (if you are starting the HP tuning from scratch you have to set the value *PRETRAINED_DIR*, if you are restarting the HP tuning from a previous saved checkpoint you have to set the value *MODEL_DIR*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1a1TxFNKmx"
      },
      "source": [
        "## this is useful if you have more than one task\n",
        "# def _rate_num_input_examples(task):\n",
        "#   if \"train\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"train\"))\n",
        "#   elif \"validation\" in task.splits:\n",
        "#     return float(task.num_input_examples(\"validation\"))\n",
        "#   else:\n",
        "#     raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "# t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "# t5.data.MixtureRegistry.add(\n",
        "#     \"all_tasks\",\n",
        "#     [\"java_construct\", \"java_token\", \"java_block\", \"android_construct\", \"android_token\", \"android_block\"],\n",
        "#     default_rate=_rate_num_input_examples\n",
        "#      #default_rate=1.0\n",
        "# )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular\n",
        "\n",
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/finetuning/0807/model'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 5000),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = slanted_triangular,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oHp5ScE7nf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fa5a41-0df8-4877-b714-1aa379d6bcdf"
      },
      "source": [
        "PATH_GIN_FILE = 'gs://bucket_block_completion/finetuning/0807/operative_config_slanted.gin'\n",
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 470000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"finetuning\",\n",
        "        pretrained_model_dir=MODEL_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0807/operative_config_slanted.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0807/operative_config_slanted.gin\n",
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0807/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0807/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0807/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.39.255.178:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.39.255.178:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.39.255.178:8470', '_evaluation_master': 'grpc://10.39.255.178:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe08b998c10>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.39.255.178:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.39.255.178:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -6811897859439975572)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -163341402620552156)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 977843658680354213)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -7062366406084269183)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -6488360689951971688)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -1698389718113268917)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7195573971099586859)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7331477743768100068)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5513766074524010244)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -6844290616326784761)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -6353694097469733064)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:401: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('vocab', 'model'), ('d_ff', 'model'), ('batch', 'batch'), ('ensemble', 'ensemble'), ('experts', 'batch'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe0877e2210>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 6.85e+08\n",
            " allreduce/[0]: 6.85e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 2.01e+08\n",
            "einsum: 4.06e+13\n",
            "einsum_unique: 4.05e+13\n",
            "output: 3.66e+11\n",
            " output/AddOperation: 6.7e+10\n",
            " output/BinaryOpWithBroadcasting: 4.51e+09\n",
            " output/BroadcastOperation: 2.02e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 1.46e+11\n",
            " output/ImportOperation: 6.29e+06\n",
            " output/MinMaxOperation: 3.79e+07\n",
            " output/OneHotOperation: 1.34e+10\n",
            " output/RandomOperation: 2.96e+07\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 7.93e+09\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.39e+08\n",
            " output/ScalarMultiplyOperation: 3.64e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 7.48e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 1.39e+10\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 3.58e+11\n",
            " output_unique/AddOperation: 6.67e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 4.47e+09\n",
            " output_unique/BroadcastOperation: 2.02e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 1.42e+11\n",
            " output_unique/ImportOperation: 7.87e+05\n",
            " output_unique/MinMaxOperation: 4.85e+06\n",
            " output_unique/OneHotOperation: 1.27e+10\n",
            " output_unique/RandomOperation: 2.96e+07\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 7.76e+09\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 7.1e+07\n",
            " output_unique/ScalarMultiplyOperation: 3.55e+09\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 7.25e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 1.39e+10\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://bucket_block_completion/finetuning/0807/model/model.ckpt-664100:\n",
            "INFO:tensorflow:Variables in gs://bucket_block_completion/finetuning/0807/model/model.ckpt-664100 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://bucket_block_completion/finetuning/0807/model/model.ckpt-664100:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0807/model/model.ckpt-664100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1165: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:758: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 664100...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 664100 into gs://bucket_block_completion/finetuning/0807/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 664100...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 96)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 664200\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 90)\n",
            "INFO:tensorflow:loss = 0.12402344, step = 664300 (63.480 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5753\n",
            "INFO:tensorflow:examples/sec: 403.276\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 85)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 664400 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5831\n",
            "INFO:tensorflow:examples/sec: 405.273\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 79)\n",
            "INFO:tensorflow:loss = 0.1171875, step = 664500 (63.826 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56677\n",
            "INFO:tensorflow:examples/sec: 401.092\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 74)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 664600 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.281\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 68)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 664700 (63.799 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56743\n",
            "INFO:tensorflow:examples/sec: 401.261\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 63)\n",
            "INFO:tensorflow:loss = 0.12792969, step = 664800 (63.700 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56987\n",
            "INFO:tensorflow:examples/sec: 401.887\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 58)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 664900 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5831\n",
            "INFO:tensorflow:examples/sec: 405.274\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 53)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 665000 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.282\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 47)\n",
            "INFO:tensorflow:loss = 0.10449219, step = 665100 (63.816 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.567\n",
            "INFO:tensorflow:examples/sec: 401.152\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 42)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 665200 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58316\n",
            "INFO:tensorflow:examples/sec: 405.288\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 37)\n",
            "INFO:tensorflow:loss = 0.10449219, step = 665300 (63.709 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56964\n",
            "INFO:tensorflow:examples/sec: 401.829\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (12, 32)\n",
            "INFO:tensorflow:loss = 0.115234375, step = 665400 (63.662 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57078\n",
            "INFO:tensorflow:examples/sec: 402.12\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 27)\n",
            "INFO:tensorflow:loss = 0.1328125, step = 665500 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.283\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 22)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 665600 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58316\n",
            "INFO:tensorflow:examples/sec: 405.288\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 17)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 665700 (63.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5705\n",
            "INFO:tensorflow:examples/sec: 402.047\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (16, 12)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 665800 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5831\n",
            "INFO:tensorflow:examples/sec: 405.275\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 7)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 665900 (63.703 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56976\n",
            "INFO:tensorflow:examples/sec: 401.857\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 2)\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 98)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 666000 (63.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56379\n",
            "INFO:tensorflow:examples/sec: 400.33\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 92)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 666100 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.278\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 87)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 666200 (63.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58305\n",
            "INFO:tensorflow:examples/sec: 405.262\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (21, 82)\n",
            "INFO:tensorflow:loss = 0.123535156, step = 666300 (63.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57018\n",
            "INFO:tensorflow:examples/sec: 401.966\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 77)\n",
            "INFO:tensorflow:loss = 0.106933594, step = 666400 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.279\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (23, 72)\n",
            "INFO:tensorflow:loss = 0.12988281, step = 666500 (63.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56969\n",
            "INFO:tensorflow:examples/sec: 401.84\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 67)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 666600 (63.688 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57015\n",
            "INFO:tensorflow:examples/sec: 401.96\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 62)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 666700 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.287\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (26, 57)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 666800 (63.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58309\n",
            "INFO:tensorflow:examples/sec: 405.272\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 52)\n",
            "INFO:tensorflow:loss = 0.115234375, step = 666900 (63.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56814\n",
            "INFO:tensorflow:examples/sec: 401.445\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (28, 47)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 667000 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.284\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 42)\n",
            "INFO:tensorflow:loss = 0.115234375, step = 667100 (63.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57046\n",
            "INFO:tensorflow:examples/sec: 402.038\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 37)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 667200 (63.694 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57\n",
            "INFO:tensorflow:examples/sec: 401.92\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 32)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 667300 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.286\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (32, 27)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 667400 (63.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58307\n",
            "INFO:tensorflow:examples/sec: 405.266\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (33, 22)\n",
            "INFO:tensorflow:loss = 0.11279297, step = 667500 (63.683 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57029\n",
            "INFO:tensorflow:examples/sec: 401.995\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 17)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 667600 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.285\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (35, 11)\n",
            "INFO:tensorflow:loss = 0.10498047, step = 667700 (63.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56762\n",
            "INFO:tensorflow:examples/sec: 401.312\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 6)\n",
            "INFO:tensorflow:loss = 0.125, step = 667800 (63.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56848\n",
            "INFO:tensorflow:examples/sec: 401.53\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (37, 1)\n",
            "INFO:tensorflow:Outfeed finished for iteration (37, 97)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 667900 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58311\n",
            "INFO:tensorflow:examples/sec: 405.277\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 92)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 668000 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.278\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 87)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 668100 (63.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56967\n",
            "INFO:tensorflow:examples/sec: 401.836\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 82)\n",
            "INFO:tensorflow:loss = 0.10498047, step = 668200 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.279\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (41, 76)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 668300 (63.838 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56647\n",
            "INFO:tensorflow:examples/sec: 401.018\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (42, 71)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 668400 (63.782 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56784\n",
            "INFO:tensorflow:examples/sec: 401.366\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (43, 66)\n",
            "INFO:tensorflow:loss = 0.10449219, step = 668500 (63.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5831\n",
            "INFO:tensorflow:examples/sec: 405.275\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (44, 61)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 668600 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.284\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (45, 56)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 668700 (63.709 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56964\n",
            "INFO:tensorflow:examples/sec: 401.829\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (46, 51)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 668800 (63.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58308\n",
            "INFO:tensorflow:examples/sec: 405.268\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (47, 46)\n",
            "INFO:tensorflow:loss = 0.106933594, step = 668900 (63.765 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56826\n",
            "INFO:tensorflow:examples/sec: 401.474\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (48, 41)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 669000 (63.701 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56982\n",
            "INFO:tensorflow:examples/sec: 401.874\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (49, 36)\n",
            "INFO:tensorflow:loss = 0.13183594, step = 669100 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.28\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (50, 31)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 669200 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58316\n",
            "INFO:tensorflow:examples/sec: 405.288\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 669200...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 669200 into gs://bucket_block_completion/finetuning/0807/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 669200...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (51, 17)\n",
            "INFO:tensorflow:loss = 0.10498047, step = 669300 (69.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44135\n",
            "INFO:tensorflow:examples/sec: 368.987\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (52, 12)\n",
            "INFO:tensorflow:loss = 0.12109375, step = 669400 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58311\n",
            "INFO:tensorflow:examples/sec: 405.276\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (53, 6)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 669500 (63.842 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56632\n",
            "INFO:tensorflow:examples/sec: 400.977\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (54, 1)\n",
            "INFO:tensorflow:Outfeed finished for iteration (54, 97)\n",
            "INFO:tensorflow:loss = 0.123046875, step = 669600 (64.709 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.54543\n",
            "INFO:tensorflow:examples/sec: 395.631\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (55, 90)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 669700 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.284\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (56, 85)\n",
            "INFO:tensorflow:loss = 0.12402344, step = 669800 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.281\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (57, 80)\n",
            "INFO:tensorflow:loss = 0.12402344, step = 669900 (63.688 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57016\n",
            "INFO:tensorflow:examples/sec: 401.96\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (58, 75)\n",
            "INFO:tensorflow:loss = 0.11767578, step = 670000 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.279\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (59, 70)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 670100 (63.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5703\n",
            "INFO:tensorflow:examples/sec: 401.996\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (60, 65)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 670200 (63.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56974\n",
            "INFO:tensorflow:examples/sec: 401.854\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (61, 60)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 670300 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.287\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (62, 55)\n",
            "INFO:tensorflow:loss = 0.12597656, step = 670400 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58311\n",
            "INFO:tensorflow:examples/sec: 405.277\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (63, 50)\n",
            "INFO:tensorflow:loss = 0.119140625, step = 670500 (63.698 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56992\n",
            "INFO:tensorflow:examples/sec: 401.899\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (64, 45)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 670600 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.279\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (65, 40)\n",
            "INFO:tensorflow:loss = 0.10107422, step = 670700 (63.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56858\n",
            "INFO:tensorflow:examples/sec: 401.557\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (66, 35)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 670800 (63.735 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56899\n",
            "INFO:tensorflow:examples/sec: 401.662\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (67, 30)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 670900 (63.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58307\n",
            "INFO:tensorflow:examples/sec: 405.267\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (68, 25)\n",
            "INFO:tensorflow:loss = 0.119140625, step = 671000 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.279\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (69, 20)\n",
            "INFO:tensorflow:loss = 0.10595703, step = 671100 (63.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56773\n",
            "INFO:tensorflow:examples/sec: 401.338\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (70, 15)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 671200 (63.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5831\n",
            "INFO:tensorflow:examples/sec: 405.273\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (71, 10)\n",
            "INFO:tensorflow:loss = 0.12695312, step = 671300 (63.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5685\n",
            "INFO:tensorflow:examples/sec: 401.536\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (72, 5)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 671400 (63.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56973\n",
            "INFO:tensorflow:examples/sec: 401.85\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (73, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (73, 96)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 671500 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.286\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (74, 91)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 671600 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5831\n",
            "INFO:tensorflow:examples/sec: 405.274\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (75, 86)\n",
            "INFO:tensorflow:loss = 0.103515625, step = 671700 (63.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56969\n",
            "INFO:tensorflow:examples/sec: 401.84\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (76, 81)\n",
            "INFO:tensorflow:loss = 0.100097656, step = 671800 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5831\n",
            "INFO:tensorflow:examples/sec: 405.275\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (77, 76)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 671900 (63.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57025\n",
            "INFO:tensorflow:examples/sec: 401.985\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (78, 71)\n",
            "INFO:tensorflow:loss = 0.103515625, step = 672000 (63.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56974\n",
            "INFO:tensorflow:examples/sec: 401.854\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (79, 66)\n",
            "INFO:tensorflow:loss = 0.11376953, step = 672100 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.281\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (80, 61)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 672200 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.285\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (81, 56)\n",
            "INFO:tensorflow:loss = 0.12011719, step = 672300 (63.699 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56988\n",
            "INFO:tensorflow:examples/sec: 401.888\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (82, 51)\n",
            "INFO:tensorflow:loss = 0.115234375, step = 672400 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.281\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (83, 46)\n",
            "INFO:tensorflow:loss = 0.119140625, step = 672500 (63.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56934\n",
            "INFO:tensorflow:examples/sec: 401.75\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (84, 41)\n",
            "INFO:tensorflow:loss = 0.09472656, step = 672600 (63.688 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57015\n",
            "INFO:tensorflow:examples/sec: 401.958\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (85, 36)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 672700 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.286\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (86, 31)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 672800 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.287\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (87, 25)\n",
            "INFO:tensorflow:loss = 0.118652344, step = 672900 (63.860 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56592\n",
            "INFO:tensorflow:examples/sec: 400.876\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (88, 20)\n",
            "INFO:tensorflow:loss = 0.103515625, step = 673000 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.28\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (89, 15)\n",
            "INFO:tensorflow:loss = 0.100097656, step = 673100 (63.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56826\n",
            "INFO:tensorflow:examples/sec: 401.475\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (90, 10)\n",
            "INFO:tensorflow:loss = 0.125, step = 673200 (64.610 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5478\n",
            "INFO:tensorflow:examples/sec: 396.238\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (91, 3)\n",
            "INFO:tensorflow:Outfeed finished for iteration (91, 99)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 673300 (63.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58309\n",
            "INFO:tensorflow:examples/sec: 405.271\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (92, 94)\n",
            "INFO:tensorflow:loss = 0.10839844, step = 673400 (63.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58311\n",
            "INFO:tensorflow:examples/sec: 405.276\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (93, 89)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 673500 (63.706 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56972\n",
            "INFO:tensorflow:examples/sec: 401.848\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (94, 84)\n",
            "INFO:tensorflow:loss = 0.10498047, step = 673600 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.285\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (95, 79)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 673700 (63.725 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56924\n",
            "INFO:tensorflow:examples/sec: 401.725\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (96, 74)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 673800 (63.664 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57076\n",
            "INFO:tensorflow:examples/sec: 402.114\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (97, 69)\n",
            "INFO:tensorflow:loss = 0.119140625, step = 673900 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58315\n",
            "INFO:tensorflow:examples/sec: 405.286\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (98, 64)\n",
            "INFO:tensorflow:loss = 0.11425781, step = 674000 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.281\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (99, 58)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 674100 (63.827 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56673\n",
            "INFO:tensorflow:examples/sec: 401.083\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (100, 53)\n",
            "INFO:tensorflow:loss = 0.104003906, step = 674200 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.284\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (101, 48)\n",
            "INFO:tensorflow:loss = 0.095703125, step = 674300 (63.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56804\n",
            "INFO:tensorflow:examples/sec: 401.419\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 674300...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 674300 into gs://bucket_block_completion/finetuning/0807/model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 674300...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (102, 32)\n",
            "INFO:tensorflow:loss = 0.11035156, step = 674400 (70.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.40872\n",
            "INFO:tensorflow:examples/sec: 360.631\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (103, 27)\n",
            "INFO:tensorflow:loss = 0.09765625, step = 674500 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58312\n",
            "INFO:tensorflow:examples/sec: 405.28\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (104, 22)\n",
            "INFO:tensorflow:loss = 0.107421875, step = 674600 (63.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58314\n",
            "INFO:tensorflow:examples/sec: 405.285\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (105, 17)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 674700 (63.735 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56901\n",
            "INFO:tensorflow:examples/sec: 401.665\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (106, 12)\n",
            "INFO:tensorflow:loss = 0.123046875, step = 674800 (63.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.58313\n",
            "INFO:tensorflow:examples/sec: 405.28\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (107, 7)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 674900 (63.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.57039\n",
            "INFO:tensorflow:examples/sec: 402.019\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (108, 2)\n",
            "INFO:tensorflow:Outfeed finished for iteration (108, 98)\n",
            "INFO:tensorflow:loss = 0.110839844, step = 675000 (63.713 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.56954\n",
            "INFO:tensorflow:examples/sec: 401.803\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CviTb69IJUQ_"
      },
      "source": [
        "### Evaluate the performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJYVynoR5hDe"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 512\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"finetuning\",\n",
        "    # mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1 #evaluate only last checkpoint\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}