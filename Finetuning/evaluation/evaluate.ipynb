{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugT1qQ0XEW8U"
      },
      "source": [
        "### Configuration of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1MRzBLtex2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8283b1-e0b1-4810-983a-ce292ed71a39"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "!pip install -qU t5\n",
        "\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://bucket_block_completion\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "!pip install tensorflow-gcs-config\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "     |████████████████████████████████| 153 kB 5.5 MB/s            \n",
            "     |████████████████████████████████| 3.1 MB 54.1 MB/s            \n",
            "     |████████████████████████████████| 366 kB 40.7 MB/s            \n",
            "     |████████████████████████████████| 286 kB 56.8 MB/s            \n",
            "     |████████████████████████████████| 4.0 MB 50.9 MB/s            \n",
            "     |████████████████████████████████| 1.2 MB 30.6 MB/s            \n",
            "     |████████████████████████████████| 4.9 MB 46.3 MB/s            \n",
            "     |████████████████████████████████| 90 kB 8.7 MB/s             \n",
            "     |████████████████████████████████| 895 kB 37.0 MB/s            \n",
            "     |████████████████████████████████| 3.3 MB 31.7 MB/s            \n",
            "     |████████████████████████████████| 596 kB 53.8 MB/s            \n",
            "     |████████████████████████████████| 59 kB 5.6 MB/s             \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-gcs-config in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.37.32.138:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Poax9QWkEeMV"
      },
      "source": [
        "### Loading of the tsv test file\n",
        "We loaded the tsv files, please be sure to upload them on the bucket and to copy the correct path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0_qde87wo8Y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "source": [
        "\n",
        "nq_tsv_path = {\n",
        "    \"train\":      'gs://bucket_block_completion/dataset_08_07/train.tsv',\n",
        "    # we don't use them\n",
        "    \"validation\": 'gs://bucket_block_completion/dataset_08_07/eval.tsv',\n",
        "}\n",
        "\n",
        "num_nq_examples = dict(train=1197310, validation=15783)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Y8Tje7FiNi"
      },
      "source": [
        "### Preprocess of the dataset\n",
        "In this step we preprocess the dataset.  \n",
        "You have to change the path to vocab files (*vocab_model_path* and *vocab_path*)\n",
        "We're going to preprocess all the tsv file so that T5 can use them for HP tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WK7uMr3zYuQ"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobLvzL18zzR"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_block_completion/code.model'\n",
        "vocab_path = 'gs://bucket_block_completion/code.vocab'\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGp5FiN1yFQ",
        "outputId": "f1e28d5d-edad-4507-e3ff-e42fab9492ad"
      },
      "source": [
        "prefix=''\n",
        "\n",
        "def nq_dataset_task(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_task(\"train\").take(5)):\n",
        "    print(ex)\n",
        "\n",
        "\n",
        "def preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join([prefix + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label}\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "      \n",
        "t5.data.TaskRegistry.remove('finetuning')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"finetuning\",\n",
        "    dataset_fn=nq_dataset_task,\n",
        "    splits=[\"validation\"],\n",
        "    text_preprocessor=preprocessing,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'public static void saveBitmapToDevice(Bitmap btmp, String filePath, String imageName) { File file = new File (filePath, imageName); if (file.exists ()) file.delete (); try <extra_id_0> catch (Exception e) { e.printStackTrace(); } }', 'output': b'{ FileOutputStream out = new FileOutputStream(file); btmp.compress(Bitmap.CompressFormat.JPEG, 90, out); out.flush(); out.close(); }'}\n",
            "{'input': b'@Override public Dampening updateGroupDampening(String tenantId, Dampening groupDampening) throws Exception { if (isEmpty(tenantId)) { throw new IllegalArgumentException(\"TenantId must be not null\"); } if (isEmpty(groupDampening)) { throw new IllegalArgumentException(\"DampeningId and TriggerId must be not null\"); } try { deferNotifications(); checkTenantId(tenantId, groupDampening); String groupId = groupDampening.getTriggerId(); Trigger groupTrigger = getTrigger(tenantId, groupId); if (!groupTrigger.isGroup()) { throw new IllegalArgumentException( \"Trigger [\" + tenantId + \"/\" + groupId + \"] is not a group trigger.\"); } Collection<Trigger> memberTriggers = getMemberTriggers(tenantId, groupId, false); for (Trigger member : memberTriggers) <extra_id_0> groupDampening.setTriggerId(groupTrigger.getId()); return updateDampening(groupDampening); } finally { releaseNotifications(); } }', 'output': b'{ groupDampening.setTriggerId(member.getId()); updateDampening(groupDampening); }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) <extra_id_0> return rv.toString(); } return toXMLString(); }', 'output': b'{ XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) { XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); } }'}\n",
            "{'input': b'private String ecmaToString() { if (isAttribute() || isText()) { return ecmaValue(); } if (this.hasSimpleContent()) { StringBuilder rv = new StringBuilder(); for (int i=0; i < this.node.getChildCount(); i++) { XmlNode child = this.node.getChild(i); if (!child.isProcessingInstructionType() && !child.isCommentType()) <extra_id_0> } return rv.toString(); } return toXMLString(); }', 'output': b'{ XML x = new XML(getLib(), getParentScope(), (XMLObject)getPrototype(), child); rv.append(x.toString()); }'}\n",
            "{'input': b'private void getClassAnnotationsFromDTO(Object config, DTODescription description) <extra_id_0>', 'output': b'{ Annotation[] declaredAnnotations = getTemplateClass(config).getDeclaredAnnotations(); if (declaredAnnotations != null) { for (Annotation annotation : declaredAnnotations) { description.addAnnotation(annotation); } } }'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7fe3826a0b10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-GatnV2dLG",
        "outputId": "5e2b4263-1a8a-4eb9-9700-0e5c1817bca7"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"finetuning\")\n",
        "ds = nq_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'@Override public void setComponentComparator(Comparator<AdminComponent> comparator) { if (null == comparator) { this.components = new ConcurrentSkipListSet<>(); } else <extra_id_0> }', 'inputs': array([   19,    27,    12,    20,    55,   405,  1670,     5,  1670,\n",
            "          25,  1672,   405,    29,  4798,     8,     7,    21,    17,\n",
            "         180,    40,  4798,     8,     7,    23,     4,  7428,    11,\n",
            "          24, 11414,  3350,    71,   174,   447,     6,    77, 32099,\n",
            "           6,     1], dtype=int32), 'targets_pretokenized': b'{ Set<AdminComponent> newComponents = new ConcurrentSkipListSet<>(comparator); newComponents.addAll(this.components); this.components = newComponents; }', 'targets': array([    7,   300,    25,  1672,   405,    29,    24,  2599,    11,\n",
            "          24, 11414,  3350,    71,   174,   629,  8321,    10,    24,\n",
            "        2599,     4,   771,     5,    75,     4,  7428,    10,    23,\n",
            "           4,  7428,    11,    24,  2599,    13,     6,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'public static void orderBandsIntoRGB( ImageInterleaved image , BufferedImage input ) { if(BoofConcurrency.USE_CONCURRENT ) <extra_id_0> else { if (image instanceof InterleavedU8) { ImplConvertRaster.orderBandsIntoRGB((InterleavedU8) image, input); } else if (image instanceof InterleavedF32) { ImplConvertRaster.orderBandsIntoRGB((InterleavedF32) image, input); } else { throw new IllegalArgumentException(\"Unsupported interleaved type\"); } } }', 'inputs': array([   12,    48,    20,  1200,  4153,    22,  4334,  5575,     5,\n",
            "        2613,  6854, 20579,   101,   981,     3,     9,  6191,   297,\n",
            "           3,     8,     7,    21,     5, 12443,   579, 14664,     4,\n",
            "        4618,    15, 26344,     3,     8, 32099,    77,     7,    21,\n",
            "          17,  1445,   166,     3,  6854, 20579,   101,  1094,     2,\n",
            "           8,     7,     3,   262,  5311, 11207,     4,  1782,  4153,\n",
            "          22,  4334,  5575,     5,     5,  6854, 20579,   101,  1094,\n",
            "           2,     8,   981,     9,   297,    10,     6,    77,    21,\n",
            "          17,  1445,   166,     3,  6854, 20579,   101,   216,     2,\n",
            "         809,     7,     3,   262,  5311, 11207,     4,  1782,  4153,\n",
            "          22,  4334,  5575,     5,     5,  6854, 20579,   101,   216,\n",
            "           2,   809,   981,     9,   297,    10,     6,    77,     7,\n",
            "          78,    24,   381,    38,    28,  4794, 10234, 20579,   101,\n",
            "         147,    46,     6,     6,     6,     1], dtype=int32), 'targets_pretokenized': b'{ if (image instanceof InterleavedU8) { ImplConvertRaster_MT.orderBandsIntoRGB((InterleavedU8) image, input); } else if (image instanceof InterleavedF32) { ImplConvertRaster_MT.orderBandsIntoRGB((InterleavedF32) image, input); } else { throw new IllegalArgumentException(\"Unsupported interleaved type\"); } }', 'targets': array([    7,    21,    17,  1445,   166,     3,  6854, 20579,   101,\n",
            "        1094,     2,     8,     7,     3,   262,  5311, 11207,    15,\n",
            "        9957,     4,  1782,  4153,    22,  4334,  5575,     5,     5,\n",
            "        6854, 20579,   101,  1094,     2,     8,   981,     9,   297,\n",
            "          10,     6,    77,    21,    17,  1445,   166,     3,  6854,\n",
            "       20579,   101,   216,     2,   809,     7,     3,   262,  5311,\n",
            "       11207,    15,  9957,     4,  1782,  4153,    22,  4334,  5575,\n",
            "           5,     5,  6854, 20579,   101,   216,     2,   809,   981,\n",
            "           9,   297,    10,     6,    77,     7,    78,    24,   381,\n",
            "          38,    28,  4794, 10234, 20579,   101,   147,    46,     6,\n",
            "           6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'void tessellatePolygon(boolean solid, boolean closed, boolean calcNormals) { beginTex(); int nInVert = in.vertexCount; if (3 <= nInVert) { firstPolyIndexCache = -1; boolean clamp = clampPolygon(); callback.init(in.renderMode == RETAINED, false, calcNormals, clamp); if (fill) { gluTess.beginPolygon(); if (solid) { gluTess.setWindingRule(PGL.TESS_WINDING_NONZERO); } else { gluTess.setWindingRule(PGL.TESS_WINDING_ODD); } gluTess.beginContour(); } if (stroke) { beginPolygonStroke(); beginStrokePath(); } int i = 0; int c = 0; while (i < in.vertexCount) { int code = VERTEX; boolean brk = false; if (in.codes != null && c < in.codeCount) { code = in.codes[c++]; if (code == BREAK && c < in.codeCount) <extra_id_0> } if (brk) { if (stroke) { endStrokePath(closed); beginStrokePath(); } if (fill) { gluTess.endContour(); gluTess.beginContour(); } } if (code == BEZIER_VERTEX) { addBezierVertex(i); i += 3; } else if (code == QUADRATIC_VERTEX) { addQuadraticVertex(i); i += 2; } else if (code == CURVE_VERTEX) { addCurveVertex(i); i++; } else { addVertex(i); i++; } } if (stroke) { endStrokePath(closed); endPolygonStroke(); } if (fill) { gluTess.endContour(); gluTess.endPolygon(); } } endTex(); if (stroke) tessellateStrokePath(); }', 'inputs': array([   20,  3374,    22, 11616, 11277,  5263,     5,   257,     3,\n",
            "        9852,   111,     9,    45,  3285,     9,    45,  6102,  3325,\n",
            "          22,     8,     7,  2818, 13623,    18,    35,   446,   213,\n",
            "        6542,   132,    11,   140,     4,  5689,   182,    13,    21,\n",
            "          17,     2,   685,   446,   213,  6542,   132,     8,     7,\n",
            "         607, 10845,   163,   307,    11,   958,    45,     3, 12633,\n",
            "          11,     3, 12633,  5263,    18,   938,     4,   969,     5,\n",
            "         321,     4,  1363,   270,    40,  7572,  7699,  1232,  1011,\n",
            "           9,    76,     9,  6102,  3325,    22,     9,     3, 12633,\n",
            "          10,    21,    17,  2916,     8,     7,  5603,   779,    70,\n",
            "        6232,     4,  3090,  5263,    18,    21,    17,  9852,   111,\n",
            "           8,     7,  5603,   779,    70,  6232,     4,    63, 18204,\n",
            "         150,   821,     5,   364,  2266,     4,  4316,   113,    15,\n",
            "       30815,  1254,    15,  1066,     2,  5326,    10,     6,    77,\n",
            "           7,  5603,   779,    70,  6232,     4,    63, 18204,   150,\n",
            "         821,     5,   364,  2266,     4,  4316,   113,    15, 30815,\n",
            "        1254,    15, 16870,   228,    10,     6,  5603,   779,    70,\n",
            "        6232,     4,  3090, 30156,    18,     6,    21,    17, 10519,\n",
            "           8,     7,  2818,  5263,  7166,    18,  2818,  7166,   128,\n",
            "          18,     6,    35,    65,    11,   116,    35,   202,    11,\n",
            "         116,   317,    17,    86,   136,   140,     4,  5689,   182,\n",
            "           8,     7,    35,   732,    11,     3, 20799,     2,    13,\n",
            "          45,  4591,   684,    11,    76,    13,    21,    17,   321,\n",
            "           4, 15145,    49,    30,    91,   202,   136,   140,     4,\n",
            "         830,   182,     8,     7,   732,    11,   140,     4, 15145,\n",
            "          95,   167,  2480,    13,    21,    17,   830,    40,     3,\n",
            "       16151,    91,   202,   136,   140,     4,   830,   182,     8,\n",
            "       32099,     6,    21,    17,  4043,   684,     8,     7,    21,\n",
            "          17, 10519,     8,     7,   484,  7166,   128,     5,  5862,\n",
            "          10,  2818,  7166,   128,    18,     6,    21,    17,  2916,\n",
            "           8,     7,  5603,   779,    70,  6232,     4,   852, 30156,\n",
            "          18,  5603,   779,    70,  6232,     4,  3090, 30156,    18,\n",
            "           6,     6,    21,    17,   830,    40,     3,  6217,     2,\n",
            "       15815,    15, 20799,     2,     8,     7,   162,   285, 27294,\n",
            "        1433,     5,    86,    10,    65,   470,     3,     2,    13,\n",
            "           6,    77,    21,    17,   830,    40,     3,     2, 26775,\n",
            "       24115,  3214,    15, 20799,     2,     8,     7,   162,     2,\n",
            "        4639,   185, 20626,  1433,     5,    86,    10,    65,   470,\n",
            "        1991,     6,    77,    21,    17,   830,    40,   810, 18841,\n",
            "          15, 20799,     2,     8,     7,   162, 10012,  1433,     5,\n",
            "          86,    10,    65,   854,     6,    77,     7,   162,  1433,\n",
            "           5,    86,    10,    65,   854,     6,     6,    21,    17,\n",
            "       10519,     8,     7,   484,  7166,   128,     5,  5862,    10,\n",
            "         484,  5263,  7166,    18,     6,    21,    17,  2916,     8,\n",
            "           7,  5603,   779,    70,  6232,     4,   852, 30156,    18,\n",
            "        5603,   779,    70,  6232,     4,   852,  5263,    18,     6,\n",
            "           6,   484, 13623,    18,    21,    17, 10519,     8,  3374,\n",
            "          22, 11616, 11277,  7166,   128,    18,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'{ brk = true; code = in.codes[c++]; }', 'targets': array([    7,  4591,   684,    11,    89,    13,   732,    11,   140,\n",
            "           4, 15145,    95,   167,  2480,    13,     6,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'@Override public void process(final NeedleContext context) { Set<String> objectsUnderTestIds = context.getObjectsUnderTestIds(); for (String objectUnderTestId : objectsUnderTestIds) <extra_id_0> }', 'inputs': array([   19,    27,    12,    20,   539,     5,    64, 16434,  2347,\n",
            "          92,   130,     8,     7,   300,    25,    31,    29,  2808,\n",
            "       17201,   888,    11,   130,     4, 23659, 17201,   888,    18,\n",
            "          50,    17,    31, 28451,    68,    58,  2808, 17201,   888,\n",
            "           8, 32099,     6,     1], dtype=int32), 'targets_pretokenized': b'{ ObjectUnderTest objectUnderTestAnnotation = context.getObjectUnderTestAnnotation(objectUnderTestId); if (objectUnderTestAnnotation != null && objectUnderTestAnnotation.postConstruct()) { try { process(context.getObjectUnderTest(objectUnderTestId)); } catch (ObjectUnderTestInstantiationException e) { throw new RuntimeException(e); } } }', 'targets': array([    7,   102, 17201, 28451,   701,    11,   130,     4,  2666,\n",
            "       17201,   701,     5,   760, 17201,    68,    10,    21,    17,\n",
            "         760, 17201,   701,    49,    30,    91, 28451,   701,     4,\n",
            "        1257,  8415,    60,     7,    93,     7,   539,     5,   201,\n",
            "           4,  2666, 17201,     5,   760, 17201,    68,    79,     6,\n",
            "          97,    17,    96, 17201,  9752,    38,    57,     8,     7,\n",
            "          78,    24,     3,   468,     5,   110,    10,     6,     6,\n",
            "           6,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'public Subscriber<? super T> call(final Subscriber<? super T> child) { final Worker worker = scheduler.createWorker(); final SerializedSubscriber<T> s = new SerializedSubscriber<>(child); final SerialSubscription ssub = new SerialSubscription(); s.add(worker); s.add(ssub); return new Subscriber<T>(child) { final DebounceState<T> state = new DebounceState<>(); final Subscriber<?> self = this; private long _lastEmitTime; private final Object _locker = new Object(); @Override public void onStart() { request(Long.MAX_VALUE); } @Override public void onNext(final T t) { synchronized (_locker) { final int index = state.next(t); final long lastEmitTime = _lastEmitTime; long emitTimeout = timeout - (System.currentTimeMillis() - _lastEmitTime); if (_lastEmitTime == 0 || emitTimeout < 1) { ssub.set(Subscriptions.empty()); state.emit(index, s, self); _lastEmitTime = System.currentTimeMillis(); } else { ssub.set(worker.schedule(() -> <extra_id_0>, emitTimeout, unit)); } } } @Override public void onError(Throwable e) { s.onError(e); unsubscribe(); state.clear(); } @Override public void onCompleted() { state.emitAndComplete(s, this); } }; }', 'inputs': array([   12,     3,  4239,    25,     2,    52,   299,    29,   472,\n",
            "           5,    64,     3,  4239,    25,     2,    52,   299,    29,\n",
            "         750,     8,     7,    44,     3,  2786,  5479,    11,  5205,\n",
            "           4,   160,  2786,    18,    44,     3,  9808,  4239,    25,\n",
            "          70,    29,     3,    22,    11,    24,     3,  9808,  4239,\n",
            "         629,  1206,    10,    44,     3,  4948,  1605,     3,    22,\n",
            "        1278,    11,    24,     3,  4948,  1605,    18,     3,    22,\n",
            "           4,    67,     5, 10454,    10,     3,    22,     4,    67,\n",
            "           5,    22,  1278,    10,    14,    24,     3,  4239,    25,\n",
            "          70,    29,     5,  1206,     8,     7,    44,     3,  2560,\n",
            "       16716,   119,    25,    70,    29,   313,    11,    24,     3,\n",
            "        2560, 16716,   119,   447,    44,     3,  4239,    25,     2,\n",
            "          29,  3270,    11,    23,    13,    47,   126,     3,    15,\n",
            "         944, 22786,   199,    13,    47,    44,   102,     3,    15,\n",
            "        1467,   239,    11,    24,   102,    18,    19,    27,    12,\n",
            "          20,  6842,    16,     7,   190,     5,   397,     4,   887,\n",
            "           2,    15,   796,    10,     6,    19,    27,    12,    20,\n",
            "           3, 10055,     5,    64,   299,   244,     8,     7,   310,\n",
            "          17,    15,  1467,   239,     8,     7,    44,    35,   242,\n",
            "          11,   313,     4,   395,     5,   132,    10,    44,   126,\n",
            "         555, 22786,   199,    11,     3,    15,   944, 22786,   199,\n",
            "          13,   126,  6599,   855,    11,  1352,   139,    17,   473,\n",
            "           4,   167,  1167,    16,   139,     3,    15,   944, 22786,\n",
            "         199,    10,    21,    17,    15,   944, 22786,   199,    40,\n",
            "         157,     3,     2,  6599,   855,   136,   637,     7,     3,\n",
            "          22,  1278,     4,    63,     5,  8576,     4,  1571,    39,\n",
            "         313,     4,  8182,     5,   311,     9,     3,    22,     9,\n",
            "        3270,    10,     3,    15,   944, 22786,   199,    11,   208,\n",
            "           4,   167,  1167,    18,     6,    77,     7,     3,    22,\n",
            "        1278,     4,    63,     5, 10454,     4,  3038,     5,    16,\n",
            "         332, 32099,     9,  6599,   855,     9,  1624,    79,     6,\n",
            "           6,     6,    19,    27,    12,    20,  5595,     5,   832,\n",
            "          57,     8,     7,     3,    22,     4,  7625,     5,   110,\n",
            "          10, 14896,    18,   313,     4,   507,    18,     6,    19,\n",
            "          27,    12,    20,     3, 16392,    16,     7,   313,     4,\n",
            "        8182,   336,  1612,     5,    22,     9,    23,    10,     6,\n",
            "           6,    13,     6,     1], dtype=int32), 'targets_pretokenized': b'{ synchronized (_locker) { if (lastEmitTime == _lastEmitTime) { state.emit(index, s, self); _lastEmitTime = System.currentTimeMillis(); } } }', 'targets': array([    7,   310,    17,    15,  1467,   239,     8,     7,    21,\n",
            "          17,   944, 22786,   199,    40,     3,    15,   944, 22786,\n",
            "         199,     8,     7,   313,     4,  8182,     5,   311,     9,\n",
            "           3,    22,     9,  3270,    10,     3,    15,   944, 22786,\n",
            "         199,    11,   208,     4,   167,  1167,    18,     6,     6,\n",
            "           6,     1], dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0chadICjOT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkLJ-FpDF8CD"
      },
      "source": [
        "# Choose the dataset you want to evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSh7F89Zqb6"
      },
      "source": [
        "dataset=\"0302\" # 0807, 0605, 0403, 0302\n",
        "\n",
        "from t5 import models\n",
        "\n",
        "MODEL_SIZE = \"small\" \n",
        "\n",
        "# Set the folder where the checkpoints and all the others information will be writed\n",
        "MODEL_DIR = 'gs://bucket_block_completion/finetuning/{}/model/'.format(dataset)\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://bucket_block_completion/pretrained_model'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 256, 5000),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq0Onxfy-T_L",
        "outputId": "b3174c01-4a49-463f-cfe7-a52c8119994c"
      },
      "source": [
        "input_folder=MODEL_DIR\n",
        "output_folder=\"gs://bucket_block_completion/results/{}\".format(dataset)\n",
        "files=!gsutil ls $input_folder\n",
        "print(output_folder)\n",
        "files=[f for f in files if \".index\" in f]\n",
        "\n",
        "checkpoint=[int(f.split(\"-\")[1].replace(\".index\", \"\")) for f in files]\n",
        "\n",
        "check_every=2 # every 10k steps => 2*5000\n",
        "\n",
        "to_check=list()\n",
        "for i, k in enumerate(checkpoint):\n",
        "  if i%check_every==0:\n",
        "    to_check.append(k)\n",
        "\n",
        "to_check.append(checkpoint[-1])\n",
        "to_check=list(set(to_check))\n",
        "\n",
        "to_check.sort()\n",
        "\n",
        "for f in to_check:\n",
        "  print(f)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://bucket_block_completion/results/0302\n",
            "281600\n",
            "291800\n",
            "302000\n",
            "312200\n",
            "322400\n",
            "332600\n",
            "342800\n",
            "353000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKeCgqAkKIDO",
        "outputId": "c3b311eb-9632-4a8e-f162-eda693767d6c"
      },
      "source": [
        "# we used model.predict function (setting beam_size)\n",
        "import os\n",
        "input_file='gs://bucket_block_completion/HP_TUNING/slanted/model/validation_eval/finetuning_inputs'\n",
        "# you can keep the same output file; by default when predicting it added the number of steps so the file is not overwritten\n",
        "output_file=os.path.join(output_folder, \"predictions.txt\")\n",
        "print(output_file)\n",
        "\n",
        "from t5.seqio import SentencePieceVocabulary\n",
        "\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://bucket_block_completion/code.model'\n",
        "vocab_path = 'gs://bucket_block_completion/code.vocab'\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "vocabulary_predict=get_default_vocabulary()\n",
        "\n",
        "model.batch_size = 512\n",
        "\n",
        "for checkpoint in to_check:\n",
        "  print(checkpoint)\n",
        "  model.predict(input_file=input_file, output_file=output_file,\n",
        "                checkpoint_steps=checkpoint, beam_size=1, temperature=0.0, keep_top_k=-1, vocabulary=vocabulary_predict)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://bucket_block_completion/results/0302/predictions.txt\n",
            "281600\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe2818e7290>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-281600\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:825: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { total += nread; ubuff[total++] = nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { int tmp = total + nread; total = nread; obuff = new byte[tmp]; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL dependencyUrl = createArtifactUrls(plugin ⁇ mlDocument); dependencyLocations.add(dependencyUrl); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { xmin = Math.min(xmin, this.numCoordsProperty.get() - 1); ymin = Math.min(ymin, this.numCoordsProperty.get() - 1); zmin = Math.min(zmin, this.numCoordsProperty.get() - 1); zmax = Math.max(zmax, this.numCoordsProperty.get() - 1); zmax = Math.max(zmax, this.numCoordsProperty.get() - 1); }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest request = new OAuth2AuthorizationRequest(this, registrationId); request.setBasicAuth(this.authKey); return request; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String groupDate = commentGroups.get(group.getFormattedDate()); b ⁇ commentGroup.rebuildNotes(groupDate, group); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma.isOpened()) { b ⁇ jView.onResume(); } b ⁇ jView.invalidate(); }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.mBlendEnabled = enabled; if (enabled) { mBlend ⁇  =  ⁇ ; mBlend ⁇  =  ⁇ ; } else { mBlend ⁇  =  ⁇ ; } }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getLeaf()); treeIndex++; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block[] allInstances = new Block[b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(discriminator); LOGGER.debug(\"Found entity discriminator {}\", candidate.getName()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { eventData.getOldKeys().addAll(eventData.getOldKeys()); eventData.setOldKeys(eventData.getOldKeys()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { Analytics.logEventSortExpired(getContext()); m ⁇ uery.deleteAllItems(); m ⁇ uery.addItems(m ⁇ uery.getSortItems()); m ⁇ uery.notifyDataSetChanged(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 && ch ==  ⁇ \" ⁇  ) ch=readChar(); if ( ch > 0 ) pos--; return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291800\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe2803bfa90>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-291800\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[nread] = (byte)nread; obuff[nread] = (byte)ubuff[nread]; total += obuff.length; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff = new byte[nread]; obuff = new byte[nread]; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL artifactURL = createArtifactURL(containerArtifact); dependencyLocations.add(artifactURL); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double d = this.numCoordsProperty.get(i); if (d < 0) { xmin = d; ymin = d; zmax = d; } }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest request = new OAuth2AuthorizationRequest(this, registrationId); request.setApplicationName(this.getApplicationName()); return request; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String commentDate = commentGroups.get(group.getFormattedDate()); commentGroups.put(group.getFormattedDate(), comment); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (b ⁇  == null) return true; return b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇  == null  ⁇  b ⁇ \n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma.isViewAttached()) { b ⁇ view.setView(null); } return; }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.blendEnabled = enabled; if (enabled) { b ⁇ blend.setBlendEnabled(true); } else { b ⁇ blend.setBlendEnabled(false); } }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getLeafName(treeIndex)); treeWalk.addTree(tree); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block.Instance[] allInstances = new Block.Instance[this.blockList.size()]; return this.blockList.toArray(allInstances); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(candidate); LOGGER.debug(\"Found discriminator {}\", candidate.getName()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { updatedColumns.add(column.getColumnName()); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { if (m ⁇ uery.getPurchased() != null) { m ⁇ uery.getPurchased().clear(); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); start--; return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302000\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe28111c4d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-302000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { total += nread; ubuff[nread] = (byte)nread; obuff[nread] = (byte)nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff = new byte[nread]; obuff = new byte[nread]; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL artifactUrl = createArtifactUrl(containerArtifact); dependencyLocations.add(artifactUrl); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double d = this.numCoordsProperty.get(i); xmin = Math.min(xmin, d); ymin = Math.max(ymin, d); zmax = Math.min(zmax, d); zmax = Math.max(zmax, d); }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest request = new OAuth2AuthorizationRequest(this, registrationId); return new OAuth2AuthorizationRequest(request, request.getPrincipal()); }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String commentDate = commentGroups.get(group.getFormattedDate()); String groupDate = comment.getFormattedDate(); commentGroups.put(group.getFormattedDate(), group); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (b ⁇ public) { return b ⁇ public; } else if (b ⁇ public) { return b ⁇ public; } else { return b ⁇ public; } }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { b ⁇ v ⁇ .setBackgroundColor(ma.color); b ⁇ v ⁇ .setBackgroundColor(ma.color); }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.blendEnabled = enabled; b ⁇ blendEnabledSet = enabled  ⁇  b ⁇ blendEnabled : b ⁇ blendEnabled; }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getCurrentNode()); treeWalk.addTree(tree); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block.Instance[] allInstances = new Block.Instance[ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b ⁇ b\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { LOGGER.debug(\" found discriminator  ⁇ {} ⁇  for key  ⁇ {} ⁇ \", candidate.getName(), candidate.getName()); metadata.add(new EmbeddedEntityTypeMetadata<>(candidate.getSchema(), candidate.getName(), candidate.getType())); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { eventData.getOldKeys().addAll(eventData.getOldKeys()); eventData.setOldKeys(eventData.getOldKeys()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { loadData(); updateWidget(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); start--; return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312200\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe281502310>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-312200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[total++] = nread; obuff[total++] = nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), new byte[nread-nread-nread]/ ⁇ , nread-nread-nread); ubuff[total + nread] = (byte) nread; obuff[total + nread] = (byte) nread; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL artifactUrl = createArtifactUrl(containerArtifact); dependencyLocations.add(artifactUrl); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double d = (this.numCoordsProperty.get(i).x - xmin) / (this.numCoordsProperty.get(i).x - xmin); double d = (this.numCoordsProperty.get(i).y - ymin) / (this.numCoordsProperty.get(i).y - ymax); xmin = d; ymin = d; zmax = d; }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest requestWithAuthorizationRequest = new OAuth2AuthorizationRequest(this, registrationId); requestWithAuthorizationRequest.setRedirectUri(this.getRedirectUri()); return requestWithAuthorizationRequest; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String date = commentGroups.get(group.getFormattedDate()).get(\"date\"); group.setText(date); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (b ⁇  == null) b ⁇  = new b ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ newb ⁇ .b ⁇ .return ⁇ )).getReturn(); return b ⁇ .return; }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma.isOpened()) { b ⁇ .onResume(); } else { b ⁇ .onResume(); } }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.blendEnabled = enabled; if (enabled) { b ⁇ blendEnabled = false; } else { b ⁇ blendEnabled = false; } }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getCurrentNode()); treeIndex++; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block.Instance[] instances = new Block.Instance[this.instanceCount]; for (int i = 0; i < instances.length; i++) { instances[i] = new Block.Instance(this.instanceCount, i); } return instances; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { LOGGER.warn(\"More than one entity with discriminator  ⁇ {} ⁇ , but no entity is found\", key); metadata.add(candidate); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { updatedColumns.add(column.getColumnName()); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { Analytics.logEventSortExpired(getContext()); updateWidget(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇  ) { ch=readChar(); } return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322400\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe27e446a50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-322400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[nread] = (byte)nread; obuff[nread] = (byte)nread; total += nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[ ⁇ 0000] = (byte) (nread - obuff.length); obuff[ ⁇ 0000] = (byte) (nread - obuff.length); total += nread; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL containerJar = createArtifact(containerArtifact, null); dependencyLocations.add(containerJar); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double d = this.numCoordsProperty.get(i); if (d < xmin) xmin = d; if (d > ymax) ymax = d; xmax = d; zmax = d; }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest request2 = new OAuth2AuthorizationRequest(registrationId, this); this.authManager.resolve(request, request2); return request2; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String commentDate = commentGroups.get(group.getFormattedDate()); commentGroups.put(group.getFormattedDate(), group); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (b ⁇ public) { return b ⁇ public  ⁇  this.code.containsReturn(); } else { return b ⁇ public  ⁇  this.code.containsReturn(); } }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { if (ma.name.equals(LocalIDletBridge.MIDletAccess.MI ⁇ ING_MIDletAccess.NAME)) { b ⁇ uiz.onResume(); } else { b ⁇ uiz.onResume(); } }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.blendEnabled = enabled; if (enabled) { b ⁇ blendFilter.setBlendEnabled(false); b ⁇ blendFilter.setBlendEnabled(enabled); } }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getCurrentNode()); treeIndex++; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block.Instance[] allInstances = new Block.Instance[this.table.getStackSize() + 1]; for (int i = 0; i < this.table.size(); i++) { allInstances[i] = new Block.Instance(); } return allInstances; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(candidate); break; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { deletedColumns.add(column.getColumnName()); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { if (m ⁇ uery.hasItems()) { loadData(); updateWidget(); } else { m ⁇ uery.addItem(null, null); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇  ) { ch=readChar(); } return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "332600\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe27ffc1d50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-332600\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[total++] = nread; obuff[total++] = nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[total + nread] = out[total + nread]; obuff[total + nread] = obuff[(int)nread]; total += nread; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL artifactUrl = createArtifactUrl(containerArtifact); dependencyLocations.add(artifactUrl); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double d = Math.toRadians(this.numCoordsProperty.get(i)); xmin = Math.min(xmin, d); ymin = Math.max(ymin, d); zmax = Math.min(zmax, d); zmax = Math.max(zmax, d); }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest requestWithOAuth2AuthorizationRequest = new OAuth2AuthorizationRequest(registrationId, this.apiKey, this.secretKey); this.accessToken = new Token(requestWithOAuth2AuthorizationRequest.getRequestToken(), requestWithOAuth2AuthorizationRequest.getAccessToken()); return requestWithOAuth2AuthorizationRequest; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String date = commentGroups.get(group.getFormattedDate()).trim(); commentGroups.put(group.getFormattedDate(), group); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (b ⁇ es == null) b ⁇ es = new HashSet<String>(); return b ⁇ es.contains(\"return\"); }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { ma.onDisplayRepaint(new DisplayRepaintListener(this)); ma.setView(null); }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.blendEnabled = enabled; if (enabled) { b ⁇ blendFilter.setBlendEnabled(true); b ⁇ blendFilter.setBlendEnabled(enabled); } }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getCurrent()); treeIndex++; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block.Instance[] allInstances = new Block.Instance[this.numInstances]; for (int i = 0; i < allInstances.length; i++) { allInstances[i] = Block.Instance.newBuilder().setInstance(this.instances[i]).build(); } return new ArrayList<Block.Instance>(allInstances); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(candidate); LOGGER.debug(\"Found discriminator {}\", candidate.getName()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { eventData.getOldKeys().removeAll(eventData.getOldKeys()); eventData.setOldKeys(eventData.getOldKeys()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { Analytics.logEventSortExpired(getContext()); m ⁇ uery.deleteAllItems(); m ⁇ uery.addItems(m ⁇ uery.getSortItemsBy ⁇ uery()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 ) pos--; return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342800\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe281ce0dd0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-342800\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[total++] = nread; ubuff[total++] = nread; obuff[total++] = nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff = new byte[ ⁇ 0000]; System.arraycopy(ubuff, 0, ubuff, total, obuff.length); obuff = new byte[ ⁇ 0000]; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL artifactUrl = createArtifactUrl(containerArtifact); dependencyLocations.add(artifactUrl); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double d = this.numCoordsProperty.get(i); if (d < xmin) xmin = d; if (d > ymax) ymax = d; zmin = d; }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest request2 = new OAuth2AuthorizationRequest(registrationId, b ⁇ ueryService); resolve(request, request2); return request2; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String commentDate = commentGroups.get(group.getFormattedDate()); String groupDateShort = commentDate.substring(0,  ⁇ ); commentGroups.put(group.getFormattedDate(), group); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { b ⁇ public = b ⁇ public(); return b ⁇ public  ⁇  this.matches(b ⁇ public); }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { ma.loadView(); if (ma.view != null) { mB ⁇ View.setText(ma.view); } }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.enabled = enabled; b ⁇ b ⁇ Blend.setBlendEnabled(enabled); Blend.generate(this, Blend.BlendType.ORANGE); }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getCurrentNode(treeIndex)); treeIndex++; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block.Instance[] allInstances = new Block.Instance[this.table.getCreatorCount()]; for (int i = 0; i < allInstances.length; i++) { allInstances[i] = new Block.Instance(this.table.getCreatorName(i)); } return allInstances; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { LOGGER.warn(\"Found discriminator {} found in b ⁇ public, not found\", candidate.getName()); metadata.add(candidate); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { deletedColumns.add(column.getColumnName()); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { m ⁇ uery.setSort(m ⁇ uery.getSort()); m ⁇ uery.updateSort(m ⁇ uery.getSort()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇  ) { ch=readChar(); } return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:system_path_file_exists:gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n",
            "ERROR:root:Path not found: gs://bucket_block_completion/finetuning/0302/model/operative_config.gin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353000\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket_block_completion/finetuning/0302/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.37.32.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.37.32.138:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.37.32.138:8470', '_evaluation_master': 'grpc://10.37.32.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fe38089f7d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.32.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.37.32.138:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5737847261582283322)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -5627857214416643325)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7185187009604579240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 579657861411264282)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1114831591738245095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8811704591951849126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1893649660144527747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -5581643451832536902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2979194676147928295)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3711696021325263957)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 616603740087892258)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('batch', 'batch'), ('vocab', 'model'), ('experts', 'batch'), ('heads', 'model'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fe27f2e47d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 4.19e+06\n",
            " allconcat/0: 4.19e+06\n",
            "  allconcat/0/reshape_op: 4.19e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.7e+13\n",
            "einsum_unique: 2.7e+13\n",
            "output: 2.68e+11\n",
            " output/AddOperation: 6.87e+10\n",
            " output/BinaryOpWithBroadcasting: 8.61e+08\n",
            " output/Constant: 1.61e+09\n",
            " output/EinsumOperation: 6.12e+10\n",
            " output/ImportOperation: 2.1e+06\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 1.76e+10\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 8.39e+07\n",
            " output/ReshapeOperation: 1.38e+10\n",
            " output/ScalarAddOperation: 5.87e+07\n",
            " output/ScalarMultiplyOperation: 1.05e+09\n",
            " output/ShiftOperation: 2.62e+05\n",
            " output/SlicewiseOperation: 8.21e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 1.93e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 1.61e+09\n",
            "output_unique: 2.66e+11\n",
            " output_unique/AddOperation: 6.85e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 8.17e+08\n",
            " output_unique/Constant: 1.61e+09\n",
            " output_unique/EinsumOperation: 6.09e+10\n",
            " output_unique/ImportOperation: 2.62e+05\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 1.69e+10\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 8.39e+07\n",
            " output_unique/ReshapeOperation: 1.38e+10\n",
            " output_unique/ScalarAddOperation: 1.47e+07\n",
            " output_unique/ScalarMultiplyOperation: 9.62e+08\n",
            " output_unique/ShiftOperation: 2.62e+05\n",
            " output_unique/SlicewiseOperation: 8.18e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 1.93e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 1.61e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://bucket_block_completion/finetuning/0302/model/model.ckpt-353000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) <extra_id_0> if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff[total++] = nread; ubuff[total++] = nread; obuff[total++] = nread; }\n",
            "INFO:tensorflow:decoded 1: b ⁇ byte[] uncompressed( ByteBuffer buf, int offset, int uncomplen ) throws IOException { byte[] header = new byte[offset]; buf.position(0); buf.get(header); byte[] out = new byte[offset+uncomplen]; System.arraycopy(header, 0, out, 0, offset); CB ⁇ ip2InputStream cbzip2 = new CB ⁇ ip2InputStream(); int numCompBytes = buf.remaining(); byte[] bufc = new byte[numCompBytes]; buf.get(bufc, 0, numCompBytes); ByteArrayInputStream bis = new ByteArrayInputStream(bufc, 2, numCompBytes - 2); cbzip2.setStream(bis); int total = 0; int nread; byte[] ubuff = new byte[ ⁇ 0000]; byte[] obuff = new byte[ ⁇ 0000]; try { while ((nread = cbzip2.read(ubuff)) != -1) { if (total + nread > obuff.length) <extra_id_0> System.arraycopy(ubuff, 0, obuff, total, nread); total += nread; } if (obuff.length >= 0) System.arraycopy(obuff, 0, out, offset, total); } catch (B ⁇ ip2ReadException ioe) { log.warn(\"Nexrad2IOSP.uncompress \"+raf.getLocation(), ioe); } return out; } ⁇ \n",
            "INFO:tensorflow:            -> { ubuff = new byte[(int)nread]; obuff = new byte[(int)nread]; }\n",
            "INFO:tensorflow:decoded 2: b ⁇ private List<URL> addBootstrapClasspath(Document plugin ⁇ mlDocument) throws MojoFailureException, MojoExecutionException, MalformedURLException { List<Dependency> deps = new ArrayList<>(); if (containerDependencies != null) { deps.addAll(containerDependencies); } org.apache.maven.model.Dependency reststopCore = new org.apache.maven.model.Dependency(); reststopCore.setGroupId(\"org.kantega.reststop\"); reststopCore.setArtifactId(\"reststop-core\"); reststopCore.setVersion(pluginVersion); deps.add(reststopCore); List<Artifact> containerArtifacts = resolveContainerArtifacts(deps); List<URL> dependencyLocations = new ArrayList<>(containerArtifacts.size()); for (Artifact containerArtifact : containerArtifacts) <extra_id_0> return dependencyLocations; } ⁇ \n",
            "INFO:tensorflow:            -> { URL artifactUrl = createArtifactUrl(containerArtifact); dependencyLocations.add(artifactUrl); }\n",
            "INFO:tensorflow:decoded 4: b ⁇ private boolean buildLogicalBoundingBox(AlignedBox ⁇ d box) { if (this.numCoordsProperty.get()>0) { double xmin = Double.POSITIVE_INFINIT ⁇ ; double ymin = Double.POSITIVE_INFINIT ⁇ ; double zmin = Double.POSITIVE_INFINIT ⁇ ; double xmax = Double.NEGATIVE_INFINIT ⁇ ; double ymax = Double.NEGATIVE_INFINIT ⁇ ; double zmax = Double.NEGATIVE_INFINIT ⁇ ; for(int i=0; i<this.numCoordsProperty.get(); i+=  ⁇ ) <extra_id_0> box.setFromCorners(xmin, ymin, zmin, xmax, ymax, zmax); return true; } return false; } ⁇ \n",
            "INFO:tensorflow:            -> { double d = (this.numCoordsProperty.get() - i) / (this.numCoordsProperty.get() - i); if (d < xmin) xmin = d; if (d > ymax) ymax = d; zmin = d; }\n",
            "INFO:tensorflow:decoded 8: b ⁇ @Override public OAuth2AuthorizationRequest resolve(@NonNull HttpServletRequest request, String registrationId) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { OAuth2AuthorizationRequest request2 = new OAuth2AuthorizationRequest(registrationId, this.apiKey, this.secretKey); return request2; }\n",
            "INFO:tensorflow:decoded 16: b ⁇ public void rebuildCommentGroups() { long start = System.currentTimeMillis(); commentGroups = new LinkedHashMap<String, CommentGroup>(); List<Comment> expanded = Comment.expandReplies(comments); for (Comment comment : expanded) { CommentGroup group = new CommentGroup(comment); if (commentGroups.containsKey(group.getFormattedDate())) <extra_id_0> else { commentGroups.put(group.getFormattedDate(), group); } } if (BuildConfig.DEBUG) { long elapsed = System.currentTimeMillis() - start; Log.d(TAG, String.format(\"rebuildCommentGroups took:  ⁇ d [ms]\", elapsed)); } } ⁇ \n",
            "INFO:tensorflow:            -> { String commentDate = commentGroups.get(group.getFormattedDate()); b ⁇ commentGroupMgr.buildCommentGroup(group.getFormattedDate(), commentDate, group.isCommentComment()); }\n",
            "INFO:tensorflow:decoded 32: b ⁇ public boolean containsReturn() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { if (b ⁇ public) { return b ⁇ public; } else if (b ⁇ public) { return b ⁇ public; } else { return b ⁇ public; } }\n",
            "INFO:tensorflow:decoded 64: b ⁇ public void run() { MIDletAccess ma = MIDletBridge.getMIDletAccess(midlet); if (ma != null) <extra_id_0> if (contentView != null) { if (contentView instanceof AndroidRepaintListener) { ((AndroidRepaintListener) contentView).onResume(); } post(new Runnable() { public void run() { contentView.invalidate(); } }); } } ⁇ \n",
            "INFO:tensorflow:            -> { ma.load(); if (myB ⁇  != null) { myB ⁇ .setViewState(true); } }\n",
            "INFO:tensorflow:decoded 128: b ⁇ public void setBlendEnabled(final boolean enabled) <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { this.enabled = enabled; b ⁇ blendFilter.setBlendEnabled(enabled); b ⁇ blendFilter.setBlendEnabled(enabled); }\n",
            "INFO:tensorflow:decoded 256: b ⁇ public void setObject(RevTree tree, View view, Repository repo) { TreeWalk treeWalk = new TreeWalk(repo); StringBuilder sb = new StringBuilder(); try { int treeIndex = treeWalk.addTree(tree); while (treeWalk.next()) <extra_id_0> ((TextView) view.findViewById(R.id.osv_tree_description)).setText(sb); } catch (Exception e) { e.printStackTrace(); } } ⁇ \n",
            "INFO:tensorflow:            -> { sb.append(treeWalk.getCurrentNode(treeIndex)); treeIndex++; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 512: b ⁇ public List<Block.Instance> getAllInstances() <extra_id_0> ⁇ \n",
            "INFO:tensorflow:            -> { Block.Instance[] allInstances = new Block.Instance[this.numInstances]; for (int i = 0; i < allInstances.length; i++) { allInstances[i] = new Block.Instance(); } return allInstances; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: b ⁇ public DynamicType<EntityTypeMetadata<EntityMetadata>> getDynamicType(Set<Discriminator> discriminators) { return cache.computeIfAbsent(new HashSet<>(discriminators), key -> { LOGGER.debug(\"Cache miss for discriminators {}.\", key); Set<EntityTypeMetadata<EntityMetadata>> metadata = new HashSet<>(); for (Discriminator discriminator : key) { Set<EntityTypeMetadata<EntityMetadata>> candidates = typeMetadataByDiscriminator.get(discriminator); if (candidates != null) { for (EntityTypeMetadata<EntityMetadata> candidate : candidates) { Set<EntityTypeMetadata<EntityMetadata>> candidateSubTypes = aggregatedSubTypes.get(candidate); if (candidateSubTypes == null  ⁇  !containsAny(metadata, candidateSubTypes)) { Set<Discriminator> entityDiscriminators = aggregatedDiscriminators.get(candidate); if (key.size() >= entityDiscriminators.size() && key.containsAll(entityDiscriminators)) <extra_id_0> } } } } return new DynamicType<>(metadata); }); } ⁇ \n",
            "INFO:tensorflow:            -> { metadata.add(candidate); LOGGER.debug(\"Found discriminator {}\", candidate.getName()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:decoded 2048: b ⁇ private void groupFilter(EventData eventData, ColumnGroup columnGroup) { List<EventColumn> addColumns = new ArrayList<EventColumn>(); Set<String> updatedColumns = new HashSet<String>(); Set<String> pks = new HashSet<String>(); for (EventColumn column : eventData.getUpdatedColumns()) { updatedColumns.add(column.getColumnName()); } for (EventColumn pk : eventData.getKeys()) { pks.add(pk.getColumnName()); } if (!CollectionUtils.isEmpty(eventData.getOldKeys())) <extra_id_0> if (containsInGroupColumn(updatedColumns, columnGroup.getColumnPairs())) { for (ColumnPair columnPair : columnGroup.getColumnPairs()) { boolean groupColumnHasInChangedColunms = false; for (EventColumn column : eventData.getColumns()) { if (StringUtils.equalsIgnoreCase(columnPair.getSourceColumn().getName(), column.getColumnName())) { groupColumnHasInChangedColunms = true; if (!column.isUpdate()) { column.setUpdate(true); } break; } } if (!groupColumnHasInChangedColunms) { String columnName = columnPair.getSourceColumn().getName(); if (!pks.contains(columnName)) { EventColumn addColumn = new EventColumn(); addColumn.setColumnName(columnPair.getSourceColumn().getName()); addColumn.setUpdate(true); addColumns.add(addColumn); } } } if (!CollectionUtils.isEmpty(addColumns)) { eventData.getColumns().addAll(addColumns); eventData.setSyncConsistency(SyncConsistency.MEDIA); return; } } } ⁇ \n",
            "INFO:tensorflow:            -> { for (EventColumn column : eventData.getOldKeys()) { updatedColumns.add(column.getColumnName()); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: b ⁇ public void onSortChanged(int sortBy) { mCurrentSort = sortBy; if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) { Analytics.logEventSortExpired(getContext()); } else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { Analytics.logEventSortPurchaseDate(getContext()); } if (m ⁇ uery == null) { loadData(); updateWidget(); } else { if (sortBy == SORT_B ⁇ _E ⁇ PIR ⁇ ) <extra_id_0> else if (sortBy == SORT_B ⁇ _PURCHASE_DATE) { mItemsAdapter.sortItemsByPurchaseDate(); mItemsAdapter.notifyDataSetChanged(); } } } ⁇ \n",
            "INFO:tensorflow:            -> { Analytics.logEventSortExpired(getContext()); mItemsAdapter.clear(); m ⁇ uery.setSort(m ⁇ uery.getSort()); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: b ⁇ public String readNext() { int start = pos; while (true) { int ch = readChar(); if (ch<0) { String substring = text.substring(start, pos); if ( substring.length() == 0 ) { return null; } return substring; } if ( Character.isWhitespace(ch) ) { start++; } else if ( ch ==  ⁇ ( ⁇   ⁇  ch ==  ⁇ ) ⁇  ) { return text.substring(start,pos); } else if (Character.isJavaIdentifierStart(ch)) { ch=readChar(); while( Character.isJavaIdentifierPart(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( ch ==  ⁇ \" ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( ch ==  ⁇  ) { ch=readChar(); while( ch > 0 && ch !=  ⁇ ) { ch=readChar(); } return text.substring(start,pos); } else if ( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); while( Character.isDigit(ch)  ⁇  ch ==  ⁇ . ⁇  ) { ch=readChar(); } if ( ch > 0 ) pos--; return text.substring(start,pos); } else if ( !Character.isJavaIdentifierPart(ch) && ! Character.isWhitespace(ch) && ch !=  ⁇  && ch !=  ⁇ \" ⁇  ) <extra_id_0> else { start++; } } } ⁇ \n",
            "INFO:tensorflow:            -> { ch=readChar(); while( ch > 0 && ch !=  ⁇ \" ⁇  ) { ch=readChar(); } return text.substring(start,pos); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqaC_JGWIvpp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}